{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import statsmodels.stats.api as sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/nfs/turbo/umms-awaljee/wsliu/Data/NRD/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = '/home/wsliu/Codes/DLproj'\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "if module_path+'/NRD' not in sys.path:\n",
    "    sys.path.append(module_path+'/NRD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from ccs_tools import core_dtypes_pd\n",
    "from utils import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(path+'cohorts/ami/ami_pred.csv', dtype=core_dtypes_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "DX_series = pd.concat([data_df['DX'+str(j)] for j in range(2, 31)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "DX_freq = DX_series.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13131679043651512"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(DX_freq>200)/len(DX_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9543447444167605"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(DX_series.loc[DX_series.isin(DX_freq.loc[DX_freq>200].index)])/len(DX_series.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare hyper-parameters and generate the .sh files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For embedding+NN with all codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!rm hypertune*.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['no_mask']\n",
    "code_embed_dims = [200]\n",
    "fc_widths = [512]\n",
    "md_widths = [128]\n",
    "lr1s = [2e-4]\n",
    "lr2s = [2e-5]\n",
    "dropouts = [0, 0.3]\n",
    "batchsizes = [256]\n",
    "penalties = [0.]\n",
    "count_caps = [20]\n",
    "tst_seeds = range(10)\n",
    "cohorts = ['ami']\n",
    "zips = [(embed_dim, tst_fold, cohort, \n",
    "         'all/sepdx1/test_embed/cosine/embed_mat_{0}_{1:.3f}_{2}_{3}{4}.npy'.format(embed_dim, penalty, count_cap, cohort, \n",
    "                                                                                    tst_fold)) \n",
    "        for embed_dim in code_embed_dims for penalty in penalties for count_cap in count_caps for cohort in cohorts \n",
    "        for tst_fold in tst_seeds] \n",
    "#zips = zips + [(embed_dim, tst_fold, '') for embed_dim in code_embed_dims for tst_fold in tst_seeds]\n",
    "sep_dx1s = [1]\n",
    "val_folds = [7]\n",
    "rho_widths = [16]\n",
    "result_files = ['output/ht_result1121_{}.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['permutate_hosp']\n",
    "code_embed_dims = [200]\n",
    "fc_widths = [512]\n",
    "md_widths = [128]\n",
    "lr1s = [2e-4]\n",
    "lr2s = [2e-5]\n",
    "dropouts = [0]\n",
    "batchsizes = [256]\n",
    "penalties = [0.]\n",
    "count_caps = [20]\n",
    "tst_seeds = range(10)\n",
    "cohorts = ['ami']\n",
    "zips = [(embed_dim, tst_fold, cohort, \n",
    "         'all/sepdx1/test_embed/cosine/embed_mat_{0}_{1:.3f}_{2}_{3}{4}.npy'.format(embed_dim, penalty, count_cap, cohort, \n",
    "                                                                                    tst_fold)) \n",
    "        for embed_dim in code_embed_dims for penalty in penalties for count_cap in count_caps for cohort in cohorts \n",
    "        for tst_fold in tst_seeds] \n",
    "#zips = zips + [(embed_dim, tst_fold, '') for embed_dim in code_embed_dims for tst_fold in tst_seeds]\n",
    "sep_dx1s = [1]\n",
    "val_folds = [7]\n",
    "rho_widths = [16]\n",
    "result_files = ['output/ht_result1121_{}.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['batchnorm']\n",
    "code_embed_dims = [200]\n",
    "fc_widths = [512]\n",
    "md_widths = [128]\n",
    "lr1s = [2e-4]\n",
    "lr2s = [2e-5]\n",
    "dropouts = [0]\n",
    "batchsizes = [256]\n",
    "penalties = [0.]\n",
    "count_caps = [20]\n",
    "tst_seeds = range(10)\n",
    "cohorts = ['ami']\n",
    "zips = [(embed_dim, tst_fold, cohort, \n",
    "         'all/sepdx1/test_embed/cosine/embed_mat_{0}_{1:.3f}_{2}_{3}{4}.npy'.format(embed_dim, penalty, count_cap, cohort, \n",
    "                                                                                    tst_fold)) \n",
    "        for embed_dim in code_embed_dims for penalty in penalties for count_cap in count_caps for cohort in cohorts \n",
    "        for tst_fold in tst_seeds] \n",
    "#zips = zips + [(embed_dim, tst_fold, '') for embed_dim in code_embed_dims for tst_fold in tst_seeds]\n",
    "sep_dx1s = [1]\n",
    "val_folds = [7]\n",
    "rho_widths = [16]\n",
    "result_files = ['output/ht_result1121_{}.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['dense_rho']\n",
    "code_embed_dims = [200]\n",
    "fc_widths = [512]\n",
    "md_widths = [128]\n",
    "lr1s = [2e-4]\n",
    "lr2s = [2e-5]\n",
    "dropouts = [0, 0.3]\n",
    "batchsizes = [256]\n",
    "penalties = [0., 0.3]\n",
    "count_caps = [20]\n",
    "tst_seeds = range(10)\n",
    "cohorts = ['ami']\n",
    "zips = [(embed_dim, tst_fold, cohort, \n",
    "         'all/sepdx1/test_embed/cosine/embed_mat_{0}_{1:.3f}_{2}_{3}{4}.npy'.format(embed_dim, penalty, count_cap, cohort, \n",
    "                                                                                    tst_fold)) \n",
    "        for embed_dim in code_embed_dims for penalty in penalties for count_cap in count_caps for cohort in cohorts \n",
    "        for tst_fold in tst_seeds] \n",
    "#zips = zips + [(embed_dim, tst_fold, '') for embed_dim in code_embed_dims for tst_fold in tst_seeds]\n",
    "sep_dx1s = [1]\n",
    "val_folds = [7]\n",
    "rho_widths = [16, 32, 64]\n",
    "result_files = ['output/ht_result1121_{}.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_itr = itertools.product(model_names, fc_widths, md_widths, lr1s, lr2s, dropouts, batchsizes, zips, sep_dx1s, \n",
    "                             val_folds, rho_widths, result_files)\n",
    "\n",
    "para_lst = [(mo, z[0], fc, md, lr1, lr2, dr, ba, z[3], z[1], z[2], se, va, rw, re) for mo, fc, md, lr1, lr2, dr, ba, z, se, va, rw, re in para_itr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(para_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = 10\n",
    "for para, job_ind in zip(para_lst, itertools.cycle(range(n_jobs))):\n",
    "    with open('hypertune'+str(job_ind)+'.sh', 'a') as f:\n",
    "        f.write('python train_template_all0827.py --model_name {} --code_embed_dim {} --fc_width {} --md_width {} --lr1 {} --lr2 {} --dropout {} --batchsize {} --embed_file {} --tst_seed {} --cohort {} --sep_dx1 {} --val_fold {} --rho_width {} --result_file {} --job_index {}\\n'.format(*para, job_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_index = 5\n",
    "for para in para_lst:\n",
    "    with open('hypertune'+str(job_index)+'.sh', 'a') as f:\n",
    "        f.write('python train_template_all0827.py --model_name {0} --code_embed_dim {1} --fc_width {2} --md_width {3} --lr1 {4} --lr2 {5} --dropout {6} --batchsize {7} --embed_file {8} --tst_seed {9} --cohort {10} --sep_dx1 {11} --val_fold {12} --result_file {13} --job_index {14}\\n'.format(*para, job_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in [0, 1, 2, 5]:\n",
    "    for cc in [20, 100, 500]:\n",
    "        for f in range(10):\n",
    "            os.rename(path+'all/sepdx1/embed_mat_200_{:.3f}_{}_{}.npy'.format(p, cc, f), path+'all/sepdx1/embed_mat_200_{:.3f}_{}_ami{}.npy'.format(p, cc, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For embedding+NN with a subset of codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!rm hypertune*.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['setsum_nn']\n",
    "code_embed_dims = [200, 300]\n",
    "fc_widths = [512, 1024]\n",
    "md_widths = [128, 256]\n",
    "lr1s = [2e-4]\n",
    "lr2s = [2e-5]\n",
    "dropouts = [0.3]\n",
    "batchsizes = [256, 512]\n",
    "embed_mats = ['pretrain']\n",
    "penalties = [0, 0.5, 1.]\n",
    "penalty_metrics = ['cosine']\n",
    "count_caps = [0, 5, 20]\n",
    "tst_seeds = range(10)\n",
    "cohorts = ['ami']\n",
    "DX_rarecutpoints = [20]\n",
    "PR_rarecutpoints = [drp/2 for drp in DX_rarecutpoints]\n",
    "val_folds = [5]\n",
    "result_files = ['output/ht_result1001_{}.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['embed_sum', 'embed_pool']\n",
    "code_embed_dims = [100]\n",
    "fc_widths = [512]\n",
    "md_widths = [128]\n",
    "lr1s = [2e-4]\n",
    "lr2s = [2e-5]\n",
    "dropouts = [0.3]\n",
    "batchsizes = [256]\n",
    "embed_mats = ['random']\n",
    "penalties = [0]\n",
    "penalty_metrics = ['cosine']\n",
    "count_caps = [5]\n",
    "tst_seeds = range(10)\n",
    "cohorts = ['ami']\n",
    "DX_rarecutpoints = [20]\n",
    "PR_rarecutpoints = [drp/2 for drp in DX_rarecutpoints]\n",
    "val_folds = [5]\n",
    "result_files = ['output/ht_result1001_{}.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_itr = itertools.product(model_names, code_embed_dims, fc_widths, md_widths, lr1s, lr2s, dropouts, batchsizes, embed_mats, \n",
    "                             penalties, penalty_metrics, count_caps, tst_seeds, cohorts, DX_rarecutpoints,\n",
    "                             val_folds, result_files)\n",
    "para_lst = [(mn, ced, fc, md, l1, l2, do, bs, em, p, pm, cc, ts, ch, dx, int(dx/2), vf, rf) \n",
    "            for mn, ced, fc, md, l1, l2, do, bs, em, p, pm, cc, ts, ch, dx, vf, rf in para_itr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(para_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = 4\n",
    "for para, job_ind in zip(para_lst, itertools.cycle(range(n_jobs))):\n",
    "    with open('hypertune'+str(job_ind)+'.sh', 'a') as f:\n",
    "        f.write('python train_template_sub0922.py --model_name {0} --code_embed_dim {1} --fc_width {2} --md_width {3} --lr1 {4} --lr2 {5} --dropout {6} --batchsize {7} --embed_file {8} --penalty {9} --penalty_metric {10} --count_cap {11} --tst_seed {12} --cohort {13} --dx_rarecutpoint {14} --pr_rarecutpoint {15} --val_fold {16} --result_file {17} --job_index {18}\\n'.format(*para, job_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_index = 5\n",
    "for para in para_lst:\n",
    "    with open('hypertune'+str(job_index)+'.sh', 'a') as f:\n",
    "        f.write('python train_template_sub0922.py --model_name {0} --code_embed_dim {1} --fc_width {2} --md_width {3} --lr1 {4} --lr2 {5} --dropout {6} --batchsize {7} --embed_file {8} --penalty {9} --penalty_metric {10} --count_cap {11} --tst_seed {12} --cohort {13} --dx_rarecutpoint {14} --pr_rarecutpoint {15} --val_fold {16} --result_file {17} --job_index {18}\\n'.format(*para, job_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = np.random.choice(['setsum_nn'], n_sample)\n",
    "code_embed_dims = np.random.choice([200, 300], n_sample)\n",
    "fc_widths = np.random.choice([512, 1024], n_sample)\n",
    "md_widths = np.random.choice([128, 256], n_sample)\n",
    "lr1s = np.random.choice([2e-4], n_sample)\n",
    "lr2s = np.random.choice([2e-5], n_sample)\n",
    "dropouts = np.random.choice([0.3], n_sample)\n",
    "batchsizes = np.random.choice([256, 512], n_sample)\n",
    "embed_mats = np.random.choice(['pretrain'], n_sample)\n",
    "penalties = np.random.choice([0, 0.5, 1.], n_sample)\n",
    "penalty_metrics = np.random.choice(['cosine'], n_sample)\n",
    "count_caps = np.random.choice([0, 5, 20], n_sample)\n",
    "cohorts = np.random.choice(['ami'], n_sample)\n",
    "DX_rarecutpoints = np.random.choice([20], n_sample)\n",
    "PR_rarecutpoints = [int(drp/2) for drp in DX_rarecutpoints]\n",
    "val_folds = np.random.choice([5], n_sample)\n",
    "result_files = ['output/ht_result1001_{}.csv']*n_sample\n",
    "\n",
    "zips = zip(model_names, code_embed_dims, fc_widths, md_widths, lr1s, lr2s, dropouts, batchsizes, embed_mats, \n",
    "                             penalties, penalty_metrics, count_caps, cohorts, DX_rarecutpoints, PR_rarecutpoints,\n",
    "                             val_folds, result_files)\n",
    "tst_seeds = range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_itr = itertools.product(zips, tst_seeds)\n",
    "\n",
    "para_lst = [(*z, t) for z, t in para_itr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(para_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = 4\n",
    "for para, job_ind in zip(para_lst, itertools.cycle(range(n_jobs))):\n",
    "    with open('hypertune'+str(job_ind)+'.sh', 'a') as f:\n",
    "        f.write('python train_template_sub0922.py --model_name {0} --code_embed_dim {1} --fc_width {2} --md_width {3} --lr1 {4} --lr2 {5} --dropout {6} --batchsize {7} --embed_file {8} --penalty {9} --penalty_metric {10} --count_cap {11} --cohort {12} --dx_rarecutpoint {13} --pr_rarecutpoint {14} --val_fold {15} --result_file {16} --tst_seed {17} --job_index {18}\\n'.format(*para, job_ind))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For OHE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!rm hypertune*.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_width1s = [1024]\n",
    "fc_width2s = [256]\n",
    "lrs = [1e-4]\n",
    "dropouts = [0.3]\n",
    "batchsizes = [512]\n",
    "tst_seeds = range(10)\n",
    "cohorts = ['ami', 'chf', 'pna']\n",
    "val_folds = [5]\n",
    "dx_rarecutpoints = [10]\n",
    "pr_rarecutpoints = [10]\n",
    "result_files = ['output/ht_result0925_{}.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_itr = itertools.product(fc_width1s, fc_width2s, lrs, dropouts, batchsizes, tst_seeds, cohorts, val_folds, \n",
    "                             dx_rarecutpoints, pr_rarecutpoints, result_files)\n",
    "\n",
    "para_lst = list(para_itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(para_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = 1\n",
    "for para, job_ind in zip(para_lst, itertools.cycle(range(n_jobs))):\n",
    "    with open('hypertune'+str(job_ind)+'.sh', 'a') as f:\n",
    "        f.write('python train_template_ohe0925.py --fc_width1 {} --fc_width2 {} --lr {} --dropout {} --batchsize {} --tst_seed {} --cohort {} --val_fold {} --dx_rarecutpoint {} --pr_rarecutpoint {} --result_file {} --job_index {}\\n'.format(*para, job_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_index = 5\n",
    "for para in para_lst:\n",
    "    with open('hypertune'+str(job_index)+'.sh', 'a') as f:\n",
    "        f.write('python train_template_all0827.py --model_name {0} --code_embed_dim {1} --fc_width {2} --md_width {3} --lr1 {4} --lr2 {5} --dropout {6} --batchsize {7} --embed_file {8} --tst_seed {9} --cohort {10} --sep_dx1 {11} --val_fold {12} --result_file {13} --job_index {14}\\n'.format(*para, job_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding + NN with all codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for job_ind in range(10):\n",
    "    df = pd.read_csv('output/ht_result1121_'+str(job_ind)+'.csv', \n",
    "                     names=['model_name', 'code_embed_dim', 'hosp_embed_dim', 'fc_width', 'md_width', 'lr1', 'lr2', 'dropout',\n",
    "                            'batchsize', 'embed_file', 'cohort', 'sep_dx1', 'tst_seed', 'n_fold', 'auc_mean', 'auc_avg', \n",
    "                            'auc_freeze', 'rho_width', 'y_pred_file'], index_col=None)\n",
    "    res = pd.concat([res, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.assign(cohort_seed=res.cohort+res.tst_seed.apply(lambda x:str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.drop_duplicates(subset=['cohort_seed'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>code_embed_dim</th>\n",
       "      <th>hosp_embed_dim</th>\n",
       "      <th>fc_width</th>\n",
       "      <th>md_width</th>\n",
       "      <th>lr1</th>\n",
       "      <th>lr2</th>\n",
       "      <th>dropout</th>\n",
       "      <th>batchsize</th>\n",
       "      <th>embed_file</th>\n",
       "      <th>cohort</th>\n",
       "      <th>sep_dx1</th>\n",
       "      <th>tst_seed</th>\n",
       "      <th>n_fold</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_avg</th>\n",
       "      <th>auc_freeze</th>\n",
       "      <th>rho_width</th>\n",
       "      <th>y_pred_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>batchnorm</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7135</td>\n",
       "      <td>0.7198</td>\n",
       "      <td>0.7098</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_21_10_42_42.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_mask</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7193</td>\n",
       "      <td>0.7215</td>\n",
       "      <td>0.7174</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_22_07_09_18.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no_mask</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7193</td>\n",
       "      <td>0.7211</td>\n",
       "      <td>0.7180</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_22_08_04_24.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>permutate_hosp</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7176</td>\n",
       "      <td>0.7204</td>\n",
       "      <td>0.7163</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_22_08_59_26.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7186</td>\n",
       "      <td>0.7214</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_22_03_15_29.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7181</td>\n",
       "      <td>0.7217</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>32</td>\n",
       "      <td>output/y_pred_mat18_11_22_04_12_47.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7097</td>\n",
       "      <td>0.7128</td>\n",
       "      <td>0.7094</td>\n",
       "      <td>64</td>\n",
       "      <td>output/y_pred_mat18_11_22_05_10_14.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7180</td>\n",
       "      <td>0.7209</td>\n",
       "      <td>0.7167</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_22_06_08_50.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7181</td>\n",
       "      <td>0.7215</td>\n",
       "      <td>0.7185</td>\n",
       "      <td>32</td>\n",
       "      <td>output/y_pred_mat18_11_22_07_06_23.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7104</td>\n",
       "      <td>0.7132</td>\n",
       "      <td>0.7099</td>\n",
       "      <td>64</td>\n",
       "      <td>output/y_pred_mat18_11_22_08_04_42.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>batchnorm</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7144</td>\n",
       "      <td>0.7225</td>\n",
       "      <td>0.7128</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_21_10_40_10.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_mask</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7243</td>\n",
       "      <td>0.7273</td>\n",
       "      <td>0.7239</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_22_07_10_32.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no_mask</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7248</td>\n",
       "      <td>0.7272</td>\n",
       "      <td>0.7247</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_22_08_06_54.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>permutate_hosp</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7225</td>\n",
       "      <td>0.7252</td>\n",
       "      <td>0.7212</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_22_09_01_47.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7181</td>\n",
       "      <td>0.7211</td>\n",
       "      <td>0.7169</td>\n",
       "      <td>32</td>\n",
       "      <td>output/y_pred_mat18_11_22_03_15_24.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7197</td>\n",
       "      <td>0.7228</td>\n",
       "      <td>0.7189</td>\n",
       "      <td>64</td>\n",
       "      <td>output/y_pred_mat18_11_22_04_12_58.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7155</td>\n",
       "      <td>0.7185</td>\n",
       "      <td>0.7147</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_22_05_11_25.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7177</td>\n",
       "      <td>0.7207</td>\n",
       "      <td>0.7165</td>\n",
       "      <td>32</td>\n",
       "      <td>output/y_pred_mat18_11_22_06_09_53.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7198</td>\n",
       "      <td>0.7229</td>\n",
       "      <td>0.7189</td>\n",
       "      <td>64</td>\n",
       "      <td>output/y_pred_mat18_11_22_07_09_14.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7154</td>\n",
       "      <td>0.7183</td>\n",
       "      <td>0.7148</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_22_08_06_56.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>batchnorm</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7065</td>\n",
       "      <td>0.7133</td>\n",
       "      <td>0.7029</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_21_11_54_07.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_mask</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7159</td>\n",
       "      <td>0.7186</td>\n",
       "      <td>0.7153</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_22_07_09_46.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no_mask</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7166</td>\n",
       "      <td>0.7187</td>\n",
       "      <td>0.7158</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_22_08_04_46.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>permutate_hosp</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7167</td>\n",
       "      <td>0.7191</td>\n",
       "      <td>0.7151</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_22_08_58_58.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7192</td>\n",
       "      <td>0.7222</td>\n",
       "      <td>0.7172</td>\n",
       "      <td>64</td>\n",
       "      <td>output/y_pred_mat18_11_22_03_15_13.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7220</td>\n",
       "      <td>0.7250</td>\n",
       "      <td>0.7212</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_22_04_12_47.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7161</td>\n",
       "      <td>0.7194</td>\n",
       "      <td>0.7154</td>\n",
       "      <td>32</td>\n",
       "      <td>output/y_pred_mat18_11_22_05_09_31.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7185</td>\n",
       "      <td>0.7214</td>\n",
       "      <td>0.7174</td>\n",
       "      <td>64</td>\n",
       "      <td>output/y_pred_mat18_11_22_06_07_41.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7211</td>\n",
       "      <td>0.7242</td>\n",
       "      <td>0.7202</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_22_07_06_03.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7159</td>\n",
       "      <td>0.7192</td>\n",
       "      <td>0.7158</td>\n",
       "      <td>32</td>\n",
       "      <td>output/y_pred_mat18_11_22_08_05_01.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>batchnorm</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7061</td>\n",
       "      <td>0.7134</td>\n",
       "      <td>0.7024</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_22_02_24_28.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_mask</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7166</td>\n",
       "      <td>0.7189</td>\n",
       "      <td>0.7157</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_22_09_56_33.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no_mask</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7165</td>\n",
       "      <td>0.7185</td>\n",
       "      <td>0.7161</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_22_10_50_55.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>permutate_hosp</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7152</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>0.7144</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_22_11_44_49.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7156</td>\n",
       "      <td>0.7191</td>\n",
       "      <td>0.7152</td>\n",
       "      <td>32</td>\n",
       "      <td>output/y_pred_mat18_11_22_09_04_40.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7142</td>\n",
       "      <td>0.7172</td>\n",
       "      <td>0.7128</td>\n",
       "      <td>64</td>\n",
       "      <td>output/y_pred_mat18_11_22_10_02_10.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7257</td>\n",
       "      <td>0.7289</td>\n",
       "      <td>0.7253</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_22_10_59_13.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7146</td>\n",
       "      <td>0.7179</td>\n",
       "      <td>0.7144</td>\n",
       "      <td>32</td>\n",
       "      <td>output/y_pred_mat18_11_22_11_57_44.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7132</td>\n",
       "      <td>0.7161</td>\n",
       "      <td>0.7125</td>\n",
       "      <td>64</td>\n",
       "      <td>output/y_pred_mat18_11_23_12_56_32.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7249</td>\n",
       "      <td>0.7279</td>\n",
       "      <td>0.7243</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_23_01_55_01.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>batchnorm</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7180</td>\n",
       "      <td>0.7264</td>\n",
       "      <td>0.7132</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_22_02_24_43.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_mask</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7270</td>\n",
       "      <td>0.7297</td>\n",
       "      <td>0.7264</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_22_09_56_15.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no_mask</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7277</td>\n",
       "      <td>0.7302</td>\n",
       "      <td>0.7274</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_22_10_50_47.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>permutate_hosp</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7258</td>\n",
       "      <td>0.7285</td>\n",
       "      <td>0.7245</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_22_11_45_31.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7157</td>\n",
       "      <td>0.7191</td>\n",
       "      <td>0.7149</td>\n",
       "      <td>64</td>\n",
       "      <td>output/y_pred_mat18_11_22_09_05_43.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7095</td>\n",
       "      <td>0.7133</td>\n",
       "      <td>0.7095</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_22_10_02_59.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7250</td>\n",
       "      <td>0.7285</td>\n",
       "      <td>0.7246</td>\n",
       "      <td>32</td>\n",
       "      <td>output/y_pred_mat18_11_22_11_01_13.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7143</td>\n",
       "      <td>0.7180</td>\n",
       "      <td>0.7139</td>\n",
       "      <td>64</td>\n",
       "      <td>output/y_pred_mat18_11_22_11_59_47.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7095</td>\n",
       "      <td>0.7121</td>\n",
       "      <td>0.7082</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_23_12_58_21.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7249</td>\n",
       "      <td>0.7278</td>\n",
       "      <td>0.7245</td>\n",
       "      <td>32</td>\n",
       "      <td>output/y_pred_mat18_11_23_01_56_39.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>batchnorm</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7182</td>\n",
       "      <td>0.7255</td>\n",
       "      <td>0.7155</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_21_09_04_12.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_mask</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7261</td>\n",
       "      <td>0.7288</td>\n",
       "      <td>0.7253</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_22_09_56_35.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no_mask</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7266</td>\n",
       "      <td>0.7289</td>\n",
       "      <td>0.7258</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_22_10_52_42.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>permutate_hosp</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7256</td>\n",
       "      <td>0.7281</td>\n",
       "      <td>0.7251</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_22_11_47_17.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7183</td>\n",
       "      <td>0.7211</td>\n",
       "      <td>0.7172</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_22_09_05_53.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7093</td>\n",
       "      <td>0.7127</td>\n",
       "      <td>0.7096</td>\n",
       "      <td>32</td>\n",
       "      <td>output/y_pred_mat18_11_22_10_03_50.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7252</td>\n",
       "      <td>0.7284</td>\n",
       "      <td>0.7242</td>\n",
       "      <td>64</td>\n",
       "      <td>output/y_pred_mat18_11_22_11_00_47.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7176</td>\n",
       "      <td>0.7212</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>16</td>\n",
       "      <td>output/y_pred_mat18_11_23_12_00_16.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7085</td>\n",
       "      <td>0.7121</td>\n",
       "      <td>0.7085</td>\n",
       "      <td>32</td>\n",
       "      <td>output/y_pred_mat18_11_23_12_58_23.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dense_rho</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>all/sepdx1/test_embed/cosine/embed_mat_200_0.0...</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7258</td>\n",
       "      <td>0.7285</td>\n",
       "      <td>0.7247</td>\n",
       "      <td>64</td>\n",
       "      <td>output/y_pred_mat18_11_23_01_57_23.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        model_name  code_embed_dim  hosp_embed_dim  fc_width  md_width  \\\n",
       "0        batchnorm             200               1       512       128   \n",
       "1          no_mask             200               1       512       128   \n",
       "2          no_mask             200               1       512       128   \n",
       "3   permutate_hosp             200               1       512       128   \n",
       "4        dense_rho             200               1       512       128   \n",
       "5        dense_rho             200               1       512       128   \n",
       "6        dense_rho             200               1       512       128   \n",
       "7        dense_rho             200               1       512       128   \n",
       "8        dense_rho             200               1       512       128   \n",
       "9        dense_rho             200               1       512       128   \n",
       "0        batchnorm             200               1       512       128   \n",
       "1          no_mask             200               1       512       128   \n",
       "2          no_mask             200               1       512       128   \n",
       "3   permutate_hosp             200               1       512       128   \n",
       "4        dense_rho             200               1       512       128   \n",
       "5        dense_rho             200               1       512       128   \n",
       "6        dense_rho             200               1       512       128   \n",
       "7        dense_rho             200               1       512       128   \n",
       "8        dense_rho             200               1       512       128   \n",
       "9        dense_rho             200               1       512       128   \n",
       "0        batchnorm             200               1       512       128   \n",
       "1          no_mask             200               1       512       128   \n",
       "2          no_mask             200               1       512       128   \n",
       "3   permutate_hosp             200               1       512       128   \n",
       "4        dense_rho             200               1       512       128   \n",
       "5        dense_rho             200               1       512       128   \n",
       "6        dense_rho             200               1       512       128   \n",
       "7        dense_rho             200               1       512       128   \n",
       "8        dense_rho             200               1       512       128   \n",
       "9        dense_rho             200               1       512       128   \n",
       "..             ...             ...             ...       ...       ...   \n",
       "0        batchnorm             200               1       512       128   \n",
       "1          no_mask             200               1       512       128   \n",
       "2          no_mask             200               1       512       128   \n",
       "3   permutate_hosp             200               1       512       128   \n",
       "4        dense_rho             200               1       512       128   \n",
       "5        dense_rho             200               1       512       128   \n",
       "6        dense_rho             200               1       512       128   \n",
       "7        dense_rho             200               1       512       128   \n",
       "8        dense_rho             200               1       512       128   \n",
       "9        dense_rho             200               1       512       128   \n",
       "0        batchnorm             200               1       512       128   \n",
       "1          no_mask             200               1       512       128   \n",
       "2          no_mask             200               1       512       128   \n",
       "3   permutate_hosp             200               1       512       128   \n",
       "4        dense_rho             200               1       512       128   \n",
       "5        dense_rho             200               1       512       128   \n",
       "6        dense_rho             200               1       512       128   \n",
       "7        dense_rho             200               1       512       128   \n",
       "8        dense_rho             200               1       512       128   \n",
       "9        dense_rho             200               1       512       128   \n",
       "0        batchnorm             200               1       512       128   \n",
       "1          no_mask             200               1       512       128   \n",
       "2          no_mask             200               1       512       128   \n",
       "3   permutate_hosp             200               1       512       128   \n",
       "4        dense_rho             200               1       512       128   \n",
       "5        dense_rho             200               1       512       128   \n",
       "6        dense_rho             200               1       512       128   \n",
       "7        dense_rho             200               1       512       128   \n",
       "8        dense_rho             200               1       512       128   \n",
       "9        dense_rho             200               1       512       128   \n",
       "\n",
       "       lr1      lr2  dropout  batchsize  \\\n",
       "0   0.0002  0.00002      0.0        256   \n",
       "1   0.0002  0.00002      0.0        256   \n",
       "2   0.0002  0.00002      0.3        256   \n",
       "3   0.0002  0.00002      0.0        256   \n",
       "4   0.0002  0.00002      0.0        256   \n",
       "5   0.0002  0.00002      0.0        256   \n",
       "6   0.0002  0.00002      0.0        256   \n",
       "7   0.0002  0.00002      0.3        256   \n",
       "8   0.0002  0.00002      0.3        256   \n",
       "9   0.0002  0.00002      0.3        256   \n",
       "0   0.0002  0.00002      0.0        256   \n",
       "1   0.0002  0.00002      0.0        256   \n",
       "2   0.0002  0.00002      0.3        256   \n",
       "3   0.0002  0.00002      0.0        256   \n",
       "4   0.0002  0.00002      0.0        256   \n",
       "5   0.0002  0.00002      0.0        256   \n",
       "6   0.0002  0.00002      0.0        256   \n",
       "7   0.0002  0.00002      0.3        256   \n",
       "8   0.0002  0.00002      0.3        256   \n",
       "9   0.0002  0.00002      0.3        256   \n",
       "0   0.0002  0.00002      0.0        256   \n",
       "1   0.0002  0.00002      0.0        256   \n",
       "2   0.0002  0.00002      0.3        256   \n",
       "3   0.0002  0.00002      0.0        256   \n",
       "4   0.0002  0.00002      0.0        256   \n",
       "5   0.0002  0.00002      0.0        256   \n",
       "6   0.0002  0.00002      0.0        256   \n",
       "7   0.0002  0.00002      0.3        256   \n",
       "8   0.0002  0.00002      0.3        256   \n",
       "9   0.0002  0.00002      0.3        256   \n",
       "..     ...      ...      ...        ...   \n",
       "0   0.0002  0.00002      0.0        256   \n",
       "1   0.0002  0.00002      0.0        256   \n",
       "2   0.0002  0.00002      0.3        256   \n",
       "3   0.0002  0.00002      0.0        256   \n",
       "4   0.0002  0.00002      0.0        256   \n",
       "5   0.0002  0.00002      0.0        256   \n",
       "6   0.0002  0.00002      0.0        256   \n",
       "7   0.0002  0.00002      0.3        256   \n",
       "8   0.0002  0.00002      0.3        256   \n",
       "9   0.0002  0.00002      0.3        256   \n",
       "0   0.0002  0.00002      0.0        256   \n",
       "1   0.0002  0.00002      0.0        256   \n",
       "2   0.0002  0.00002      0.3        256   \n",
       "3   0.0002  0.00002      0.0        256   \n",
       "4   0.0002  0.00002      0.0        256   \n",
       "5   0.0002  0.00002      0.0        256   \n",
       "6   0.0002  0.00002      0.0        256   \n",
       "7   0.0002  0.00002      0.3        256   \n",
       "8   0.0002  0.00002      0.3        256   \n",
       "9   0.0002  0.00002      0.3        256   \n",
       "0   0.0002  0.00002      0.0        256   \n",
       "1   0.0002  0.00002      0.0        256   \n",
       "2   0.0002  0.00002      0.3        256   \n",
       "3   0.0002  0.00002      0.0        256   \n",
       "4   0.0002  0.00002      0.0        256   \n",
       "5   0.0002  0.00002      0.0        256   \n",
       "6   0.0002  0.00002      0.0        256   \n",
       "7   0.0002  0.00002      0.3        256   \n",
       "8   0.0002  0.00002      0.3        256   \n",
       "9   0.0002  0.00002      0.3        256   \n",
       "\n",
       "                                           embed_file cohort  sep_dx1  \\\n",
       "0   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "1   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "2   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "3   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "4   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "5   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "6   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "7   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "8   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "9   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "0   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "1   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "2   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "3   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "4   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "5   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "6   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "7   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "8   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "9   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "0   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "1   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "2   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "3   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "4   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "5   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "6   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "7   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "8   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "9   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "..                                                ...    ...      ...   \n",
       "0   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "1   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "2   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "3   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "4   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "5   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "6   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "7   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "8   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "9   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "0   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "1   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "2   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "3   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "4   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "5   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "6   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "7   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "8   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "9   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "0   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "1   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "2   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "3   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "4   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "5   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "6   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "7   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "8   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "9   all/sepdx1/test_embed/cosine/embed_mat_200_0.0...    ami        1   \n",
       "\n",
       "    tst_seed  n_fold  auc_mean  auc_avg  auc_freeze  rho_width  \\\n",
       "0          0       7    0.7135   0.7198      0.7098         16   \n",
       "1          0       7    0.7193   0.7215      0.7174         16   \n",
       "2          0       7    0.7193   0.7211      0.7180         16   \n",
       "3          0       7    0.7176   0.7204      0.7163         16   \n",
       "4          0       7    0.7186   0.7214      0.7178         16   \n",
       "5          3       7    0.7181   0.7217      0.7178         32   \n",
       "6          6       7    0.7097   0.7128      0.7094         64   \n",
       "7          0       7    0.7180   0.7209      0.7167         16   \n",
       "8          3       7    0.7181   0.7215      0.7185         32   \n",
       "9          6       7    0.7104   0.7132      0.7099         64   \n",
       "0          1       7    0.7144   0.7225      0.7128         16   \n",
       "1          1       7    0.7243   0.7273      0.7239         16   \n",
       "2          1       7    0.7248   0.7272      0.7247         16   \n",
       "3          1       7    0.7225   0.7252      0.7212         16   \n",
       "4          0       7    0.7181   0.7211      0.7169         32   \n",
       "5          3       7    0.7197   0.7228      0.7189         64   \n",
       "6          7       7    0.7155   0.7185      0.7147         16   \n",
       "7          0       7    0.7177   0.7207      0.7165         32   \n",
       "8          3       7    0.7198   0.7229      0.7189         64   \n",
       "9          7       7    0.7154   0.7183      0.7148         16   \n",
       "0          2       7    0.7065   0.7133      0.7029         16   \n",
       "1          2       7    0.7159   0.7186      0.7153         16   \n",
       "2          2       7    0.7166   0.7187      0.7158         16   \n",
       "3          2       7    0.7167   0.7191      0.7151         16   \n",
       "4          0       7    0.7192   0.7222      0.7172         64   \n",
       "5          4       7    0.7220   0.7250      0.7212         16   \n",
       "6          7       7    0.7161   0.7194      0.7154         32   \n",
       "7          0       7    0.7185   0.7214      0.7174         64   \n",
       "8          4       7    0.7211   0.7242      0.7202         16   \n",
       "9          7       7    0.7159   0.7192      0.7158         32   \n",
       "..       ...     ...       ...      ...         ...        ...   \n",
       "0          7       7    0.7061   0.7134      0.7024         16   \n",
       "1          7       7    0.7166   0.7189      0.7157         16   \n",
       "2          7       7    0.7165   0.7185      0.7161         16   \n",
       "3          7       7    0.7152   0.7178      0.7144         16   \n",
       "4          2       7    0.7156   0.7191      0.7152         32   \n",
       "5          5       7    0.7142   0.7172      0.7128         64   \n",
       "6          9       7    0.7257   0.7289      0.7253         16   \n",
       "7          2       7    0.7146   0.7179      0.7144         32   \n",
       "8          5       7    0.7132   0.7161      0.7125         64   \n",
       "9          9       7    0.7249   0.7279      0.7243         16   \n",
       "0          8       7    0.7180   0.7264      0.7132         16   \n",
       "1          8       7    0.7270   0.7297      0.7264         16   \n",
       "2          8       7    0.7277   0.7302      0.7274         16   \n",
       "3          8       7    0.7258   0.7285      0.7245         16   \n",
       "4          2       7    0.7157   0.7191      0.7149         64   \n",
       "5          6       7    0.7095   0.7133      0.7095         16   \n",
       "6          9       7    0.7250   0.7285      0.7246         32   \n",
       "7          2       7    0.7143   0.7180      0.7139         64   \n",
       "8          6       7    0.7095   0.7121      0.7082         16   \n",
       "9          9       7    0.7249   0.7278      0.7245         32   \n",
       "0          9       7    0.7182   0.7255      0.7155         16   \n",
       "1          9       7    0.7261   0.7288      0.7253         16   \n",
       "2          9       7    0.7266   0.7289      0.7258         16   \n",
       "3          9       7    0.7256   0.7281      0.7251         16   \n",
       "4          3       7    0.7183   0.7211      0.7172         16   \n",
       "5          6       7    0.7093   0.7127      0.7096         32   \n",
       "6          9       7    0.7252   0.7284      0.7242         64   \n",
       "7          3       7    0.7176   0.7212      0.7178         16   \n",
       "8          6       7    0.7085   0.7121      0.7085         32   \n",
       "9          9       7    0.7258   0.7285      0.7247         64   \n",
       "\n",
       "                               y_pred_file  \n",
       "0   output/y_pred_mat18_11_21_10_42_42.npy  \n",
       "1   output/y_pred_mat18_11_22_07_09_18.npy  \n",
       "2   output/y_pred_mat18_11_22_08_04_24.npy  \n",
       "3   output/y_pred_mat18_11_22_08_59_26.npy  \n",
       "4   output/y_pred_mat18_11_22_03_15_29.npy  \n",
       "5   output/y_pred_mat18_11_22_04_12_47.npy  \n",
       "6   output/y_pred_mat18_11_22_05_10_14.npy  \n",
       "7   output/y_pred_mat18_11_22_06_08_50.npy  \n",
       "8   output/y_pred_mat18_11_22_07_06_23.npy  \n",
       "9   output/y_pred_mat18_11_22_08_04_42.npy  \n",
       "0   output/y_pred_mat18_11_21_10_40_10.npy  \n",
       "1   output/y_pred_mat18_11_22_07_10_32.npy  \n",
       "2   output/y_pred_mat18_11_22_08_06_54.npy  \n",
       "3   output/y_pred_mat18_11_22_09_01_47.npy  \n",
       "4   output/y_pred_mat18_11_22_03_15_24.npy  \n",
       "5   output/y_pred_mat18_11_22_04_12_58.npy  \n",
       "6   output/y_pred_mat18_11_22_05_11_25.npy  \n",
       "7   output/y_pred_mat18_11_22_06_09_53.npy  \n",
       "8   output/y_pred_mat18_11_22_07_09_14.npy  \n",
       "9   output/y_pred_mat18_11_22_08_06_56.npy  \n",
       "0   output/y_pred_mat18_11_21_11_54_07.npy  \n",
       "1   output/y_pred_mat18_11_22_07_09_46.npy  \n",
       "2   output/y_pred_mat18_11_22_08_04_46.npy  \n",
       "3   output/y_pred_mat18_11_22_08_58_58.npy  \n",
       "4   output/y_pred_mat18_11_22_03_15_13.npy  \n",
       "5   output/y_pred_mat18_11_22_04_12_47.npy  \n",
       "6   output/y_pred_mat18_11_22_05_09_31.npy  \n",
       "7   output/y_pred_mat18_11_22_06_07_41.npy  \n",
       "8   output/y_pred_mat18_11_22_07_06_03.npy  \n",
       "9   output/y_pred_mat18_11_22_08_05_01.npy  \n",
       "..                                     ...  \n",
       "0   output/y_pred_mat18_11_22_02_24_28.npy  \n",
       "1   output/y_pred_mat18_11_22_09_56_33.npy  \n",
       "2   output/y_pred_mat18_11_22_10_50_55.npy  \n",
       "3   output/y_pred_mat18_11_22_11_44_49.npy  \n",
       "4   output/y_pred_mat18_11_22_09_04_40.npy  \n",
       "5   output/y_pred_mat18_11_22_10_02_10.npy  \n",
       "6   output/y_pred_mat18_11_22_10_59_13.npy  \n",
       "7   output/y_pred_mat18_11_22_11_57_44.npy  \n",
       "8   output/y_pred_mat18_11_23_12_56_32.npy  \n",
       "9   output/y_pred_mat18_11_23_01_55_01.npy  \n",
       "0   output/y_pred_mat18_11_22_02_24_43.npy  \n",
       "1   output/y_pred_mat18_11_22_09_56_15.npy  \n",
       "2   output/y_pred_mat18_11_22_10_50_47.npy  \n",
       "3   output/y_pred_mat18_11_22_11_45_31.npy  \n",
       "4   output/y_pred_mat18_11_22_09_05_43.npy  \n",
       "5   output/y_pred_mat18_11_22_10_02_59.npy  \n",
       "6   output/y_pred_mat18_11_22_11_01_13.npy  \n",
       "7   output/y_pred_mat18_11_22_11_59_47.npy  \n",
       "8   output/y_pred_mat18_11_23_12_58_21.npy  \n",
       "9   output/y_pred_mat18_11_23_01_56_39.npy  \n",
       "0   output/y_pred_mat18_11_21_09_04_12.npy  \n",
       "1   output/y_pred_mat18_11_22_09_56_35.npy  \n",
       "2   output/y_pred_mat18_11_22_10_52_42.npy  \n",
       "3   output/y_pred_mat18_11_22_11_47_17.npy  \n",
       "4   output/y_pred_mat18_11_22_09_05_53.npy  \n",
       "5   output/y_pred_mat18_11_22_10_03_50.npy  \n",
       "6   output/y_pred_mat18_11_22_11_00_47.npy  \n",
       "7   output/y_pred_mat18_11_23_12_00_16.npy  \n",
       "8   output/y_pred_mat18_11_23_12_58_23.npy  \n",
       "9   output/y_pred_mat18_11_23_01_57_23.npy  \n",
       "\n",
       "[100 rows x 19 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    cosine\n",
       "1    cosine\n",
       "2    cosine\n",
       "3    cosine\n",
       "4    cosine\n",
       "Name: embed_file, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.embed_file.apply(lambda x:x.split('/')[3]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.assign(penalty = res.embed_file.apply(lambda x:float(x.split('_')[4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.assign(count_cap = res.embed_file.apply(lambda x:float(x.split('_')[5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.assign(metric = res.embed_file.apply(lambda x:(x.split('/')[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.loc[res.penalty==0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_grouped = res.groupby(['model_name', 'dropout', 'rho_width'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">auc_freeze</th>\n",
       "      <th colspan=\"2\" halign=\"left\">auc_mean</th>\n",
       "      <th colspan=\"2\" halign=\"left\">auc_avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th>dropout</th>\n",
       "      <th>rho_width</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>batchnorm</th>\n",
       "      <th>0.0</th>\n",
       "      <th>16</th>\n",
       "      <td>0.70791</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71102</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71813</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dense_rho</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.0</th>\n",
       "      <th>16</th>\n",
       "      <td>0.71814</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71887</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72198</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.71817</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71888</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72222</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.71808</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71928</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72252</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.3</th>\n",
       "      <th>16</th>\n",
       "      <td>0.71810</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71871</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72178</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.71784</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71839</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72168</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.71818</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71893</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72200</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">no_mask</th>\n",
       "      <th>0.0</th>\n",
       "      <th>16</th>\n",
       "      <td>0.71865</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71941</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72208</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <th>16</th>\n",
       "      <td>0.71944</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71996</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72212</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>permutate_hosp</th>\n",
       "      <th>0.0</th>\n",
       "      <th>16</th>\n",
       "      <td>0.71742</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71868</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72126</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 auc_freeze       auc_mean        auc_avg  \\\n",
       "                                       mean count     mean count     mean   \n",
       "model_name     dropout rho_width                                            \n",
       "batchnorm      0.0     16           0.70791    10  0.71102    10  0.71813   \n",
       "dense_rho      0.0     16           0.71814    10  0.71887    10  0.72198   \n",
       "                       32           0.71817    10  0.71888    10  0.72222   \n",
       "                       64           0.71808    10  0.71928    10  0.72252   \n",
       "               0.3     16           0.71810    10  0.71871    10  0.72178   \n",
       "                       32           0.71784    10  0.71839    10  0.72168   \n",
       "                       64           0.71818    10  0.71893    10  0.72200   \n",
       "no_mask        0.0     16           0.71865    10  0.71941    10  0.72208   \n",
       "               0.3     16           0.71944    10  0.71996    10  0.72212   \n",
       "permutate_hosp 0.0     16           0.71742    10  0.71868    10  0.72126   \n",
       "\n",
       "                                        \n",
       "                                 count  \n",
       "model_name     dropout rho_width        \n",
       "batchnorm      0.0     16           10  \n",
       "dense_rho      0.0     16           10  \n",
       "                       32           10  \n",
       "                       64           10  \n",
       "               0.3     16           10  \n",
       "                       32           10  \n",
       "                       64           10  \n",
       "no_mask        0.0     16           10  \n",
       "               0.3     16           10  \n",
       "permutate_hosp 0.0     16           10  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_grouped[['auc_freeze', 'auc_mean', 'auc_avg']].agg(['mean', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, g in res_grouped:\n",
    "    if g.auc_avg.mean() == res_grouped.auc_avg.mean().max():\n",
    "        best = g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ami freeze: 0.7193 (0.0017) mean: 0.7202 (0.0017) avg: 0.7222 (0.0017)\n",
      "chf freeze: 0.6298 (0.0015) mean: 0.6309 (0.0015) avg: 0.6337 (0.0015)\n",
      "pna freeze: 0.6748 (0.0011) mean: 0.6758 (0.0011) avg: 0.6782 (0.0011)\n"
     ]
    }
   ],
   "source": [
    "for n, g in res_grouped:\n",
    "    print(n, 'freeze: {0:.4f} ({1:.4f})'.format(g.auc_freeze.mean(), g.auc_freeze.std()/np.sqrt(len(g))), \n",
    "         'mean: {0:.4f} ({1:.4f})'.format(g.auc_mean.mean(), g.auc_mean.std()/np.sqrt(len(g))), \n",
    "         'avg: {0:.4f} ({1:.4f})'.format(g.auc_avg.mean(), g.auc_avg.std()/np.sqrt(len(g))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = pd.read_csv('output/ht_result0923.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>auc_avg</th>\n",
       "      <th>auc_cih</th>\n",
       "      <th>auc_cil</th>\n",
       "      <th>auc_freeze</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>batchsize</th>\n",
       "      <th>code_embed_dim</th>\n",
       "      <th>cohort</th>\n",
       "      <th>count_cap</th>\n",
       "      <th>...</th>\n",
       "      <th>lr1</th>\n",
       "      <th>lr2</th>\n",
       "      <th>md_width</th>\n",
       "      <th>metric</th>\n",
       "      <th>model_name</th>\n",
       "      <th>n_fold</th>\n",
       "      <th>penalty</th>\n",
       "      <th>sep_dx1</th>\n",
       "      <th>tst_seed</th>\n",
       "      <th>y_pred_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6771</td>\n",
       "      <td>0.6751)</td>\n",
       "      <td>(0.6735</td>\n",
       "      <td>0.6727</td>\n",
       "      <td>0.6743</td>\n",
       "      <td>256</td>\n",
       "      <td>200</td>\n",
       "      <td>pna</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>128</td>\n",
       "      <td>cosine</td>\n",
       "      <td>setsum</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>output/y_pred_mat18_09_25_06_11_36.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7210</td>\n",
       "      <td>0.7193)</td>\n",
       "      <td>(0.7185</td>\n",
       "      <td>0.7181</td>\n",
       "      <td>0.7189</td>\n",
       "      <td>256</td>\n",
       "      <td>200</td>\n",
       "      <td>ami</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>128</td>\n",
       "      <td>cosine</td>\n",
       "      <td>setsum</td>\n",
       "      <td>9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>output/y_pred_mat18_09_25_08_38_10.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7214</td>\n",
       "      <td>0.7197)</td>\n",
       "      <td>(0.7183</td>\n",
       "      <td>0.7179</td>\n",
       "      <td>0.7190</td>\n",
       "      <td>256</td>\n",
       "      <td>200</td>\n",
       "      <td>ami</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>128</td>\n",
       "      <td>cosine</td>\n",
       "      <td>setsum</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>output/y_pred_mat18_09_23_10_50_54.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>0.6233)</td>\n",
       "      <td>(0.6217</td>\n",
       "      <td>0.6213</td>\n",
       "      <td>0.6225</td>\n",
       "      <td>256</td>\n",
       "      <td>200</td>\n",
       "      <td>chf</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>128</td>\n",
       "      <td>cosine</td>\n",
       "      <td>setsum</td>\n",
       "      <td>9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>output/y_pred_mat18_09_24_10_47_35.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.6240</td>\n",
       "      <td>0.6224)</td>\n",
       "      <td>(0.6201</td>\n",
       "      <td>0.6198</td>\n",
       "      <td>0.6213</td>\n",
       "      <td>256</td>\n",
       "      <td>200</td>\n",
       "      <td>chf</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>128</td>\n",
       "      <td>cosine</td>\n",
       "      <td>setsum</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>output/y_pred_mat18_09_23_04_03_03.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.6751)</td>\n",
       "      <td>(0.6740</td>\n",
       "      <td>0.6729</td>\n",
       "      <td>0.6745</td>\n",
       "      <td>256</td>\n",
       "      <td>200</td>\n",
       "      <td>pna</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>128</td>\n",
       "      <td>cosine</td>\n",
       "      <td>setsum</td>\n",
       "      <td>9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>output/y_pred_mat18_09_24_02_33_23.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows  25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  auc_avg   auc_cih  auc_cil  auc_freeze  auc_mean  batchsize  \\\n",
       "4          NaN   0.6771   0.6751)  (0.6735      0.6727    0.6743        256   \n",
       "6          NaN   0.7210   0.7193)  (0.7185      0.7181    0.7189        256   \n",
       "10         0.0   0.7214   0.7197)  (0.7183      0.7179    0.7190        256   \n",
       "32        17.0   0.6249   0.6233)  (0.6217      0.6213    0.6225        256   \n",
       "37         4.0   0.6240   0.6224)  (0.6201      0.6198    0.6213        256   \n",
       "58        21.0   0.6770   0.6751)  (0.6740      0.6729    0.6745        256   \n",
       "\n",
       "    code_embed_dim cohort  count_cap                   ...                    \\\n",
       "4              200    pna       20.0                   ...                     \n",
       "6              200    ami       20.0                   ...                     \n",
       "10             200    ami       20.0                   ...                     \n",
       "32             200    chf       20.0                   ...                     \n",
       "37             200    chf       20.0                   ...                     \n",
       "58             200    pna       20.0                   ...                     \n",
       "\n",
       "       lr1      lr2 md_width  metric  model_name  n_fold  penalty  sep_dx1  \\\n",
       "4   0.0002  0.00002      128  cosine      setsum       9      0.0        1   \n",
       "6   0.0002  0.00002      128  cosine      setsum       9      0.5        1   \n",
       "10  0.0002  0.00002      128  cosine      setsum       9      0.0        1   \n",
       "32  0.0002  0.00002      128  cosine      setsum       9      0.5        1   \n",
       "37  0.0002  0.00002      128  cosine      setsum       9      0.0        1   \n",
       "58  0.0002  0.00002      128  cosine      setsum       9      0.5        1   \n",
       "\n",
       "   tst_seed                             y_pred_file  \n",
       "4         0  output/y_pred_mat18_09_25_06_11_36.npy  \n",
       "6         0  output/y_pred_mat18_09_25_08_38_10.npy  \n",
       "10        0  output/y_pred_mat18_09_23_10_50_54.npy  \n",
       "32        0  output/y_pred_mat18_09_24_10_47_35.npy  \n",
       "37        0  output/y_pred_mat18_09_23_04_03_03.npy  \n",
       "58        0  output/y_pred_mat18_09_24_02_33_23.npy  \n",
       "\n",
       "[6 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2.loc[res2.tst_seed==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">auc_freeze</th>\n",
       "      <th colspan=\"2\" halign=\"left\">auc_mean</th>\n",
       "      <th colspan=\"2\" halign=\"left\">auc_avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code_embed_dim</th>\n",
       "      <th>penalty</th>\n",
       "      <th>cohort</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">200</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.0</th>\n",
       "      <th>ami</th>\n",
       "      <td>0.71827</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71907</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72127</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chf</th>\n",
       "      <td>0.62946</td>\n",
       "      <td>10</td>\n",
       "      <td>0.63058</td>\n",
       "      <td>10</td>\n",
       "      <td>0.63351</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pna</th>\n",
       "      <td>0.67412</td>\n",
       "      <td>10</td>\n",
       "      <td>0.67541</td>\n",
       "      <td>10</td>\n",
       "      <td>0.67811</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.5</th>\n",
       "      <th>ami</th>\n",
       "      <td>0.71865</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71936</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72142</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chf</th>\n",
       "      <td>0.62985</td>\n",
       "      <td>10</td>\n",
       "      <td>0.63099</td>\n",
       "      <td>10</td>\n",
       "      <td>0.63403</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pna</th>\n",
       "      <td>0.67488</td>\n",
       "      <td>10</td>\n",
       "      <td>0.67588</td>\n",
       "      <td>10</td>\n",
       "      <td>0.67841</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              auc_freeze       auc_mean        auc_avg      \n",
       "                                    mean count     mean count     mean count\n",
       "code_embed_dim penalty cohort                                               \n",
       "200            0.0     ami       0.71827    10  0.71907    10  0.72127    10\n",
       "                       chf       0.62946    10  0.63058    10  0.63351    10\n",
       "                       pna       0.67412    10  0.67541    10  0.67811    10\n",
       "               0.5     ami       0.71865    10  0.71936    10  0.72142    10\n",
       "                       chf       0.62985    10  0.63099    10  0.63403    10\n",
       "                       pna       0.67488    10  0.67588    10  0.67841    10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2.groupby(['code_embed_dim', 'penalty', 'cohort'])[['auc_freeze', 'auc_mean', 'auc_avg']].agg(['mean', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('output/ht_result1121.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.read_csv('output/ht_result1009penalty0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.concat([res, res2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2b822428b978>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res.plot.scatter('penalty', 'auc_avg', xlim=(0, 1), ylim=(0.725, 0.733))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.loc[res.md_width>100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2ab55625ef28>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res.plot.scatter('fc_width', 'auc_mean', ylim=(0.71, 0.735))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2b5a2a76bf28>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res.plot.scatter('batchsize', 'auc_mean', ylim=(0.72, 0.73))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embed_file</th>\n",
       "      <th>y_pred_file</th>\n",
       "      <th>auc_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>all/embed_mat_pen6e-7.npy</td>\n",
       "      <td>output/y_pred_mat18_08_30_01_34_24.npy</td>\n",
       "      <td>0.7282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>all/embed_mat_pen9e-7.npy</td>\n",
       "      <td>output/y_pred_mat18_08_30_03_43_48.npy</td>\n",
       "      <td>0.7282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  embed_file                             y_pred_file  auc_mean\n",
       "5  all/embed_mat_pen6e-7.npy  output/y_pred_mat18_08_30_01_34_24.npy    0.7282\n",
       "8  all/embed_mat_pen9e-7.npy  output/y_pred_mat18_08_30_03_43_48.npy    0.7282"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.loc[res.auc_mean==res.auc_mean.max(), ['embed_file', 'y_pred_file', 'auc_mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>code_embed_dim</th>\n",
       "      <th>hosp_embed_dim</th>\n",
       "      <th>fc_width</th>\n",
       "      <th>md_width</th>\n",
       "      <th>lr1</th>\n",
       "      <th>lr2</th>\n",
       "      <th>dropout</th>\n",
       "      <th>batchsize</th>\n",
       "      <th>embed_file</th>\n",
       "      <th>data_file</th>\n",
       "      <th>sep_dx1</th>\n",
       "      <th>tst_seed</th>\n",
       "      <th>n_fold</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_cil</th>\n",
       "      <th>auc_cih</th>\n",
       "      <th>y_pred_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>setsum</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.1</td>\n",
       "      <td>128</td>\n",
       "      <td>all/embed_mat_pen_2_1e-6.npy</td>\n",
       "      <td>cohorts/ami/ami_pred.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7286</td>\n",
       "      <td>(0.7275</td>\n",
       "      <td>0.7298)</td>\n",
       "      <td>output/y_pred_mat18_08_30_11_48_48.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>setsum</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>all/embed_mat_pen_2_1e-6.npy</td>\n",
       "      <td>cohorts/ami/ami_pred.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7286</td>\n",
       "      <td>(0.7278</td>\n",
       "      <td>0.7295)</td>\n",
       "      <td>output/y_pred_mat18_08_30_06_42_42.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>setsum</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>256</td>\n",
       "      <td>all/embed_mat_pen_2_1e-6.npy</td>\n",
       "      <td>cohorts/ami/ami_pred.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7287</td>\n",
       "      <td>(0.7275</td>\n",
       "      <td>0.7300)</td>\n",
       "      <td>output/y_pred_mat18_08_30_11_59_33.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>setsum</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.1</td>\n",
       "      <td>256</td>\n",
       "      <td>all/embed_mat_pen_2_1e-6.npy</td>\n",
       "      <td>cohorts/ami/ami_pred.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7286</td>\n",
       "      <td>(0.7271</td>\n",
       "      <td>0.7301)</td>\n",
       "      <td>output/y_pred_mat18_08_30_08_38_31.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>setsum</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.5</td>\n",
       "      <td>256</td>\n",
       "      <td>all/embed_mat_pen_2_1e-6.npy</td>\n",
       "      <td>cohorts/ami/ami_pred.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7286</td>\n",
       "      <td>(0.7278</td>\n",
       "      <td>0.7294)</td>\n",
       "      <td>output/y_pred_mat18_08_30_12_04_01.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_name  code_embed_dim  hosp_embed_dim  fc_width  md_width     lr1  \\\n",
       "26     setsum             100               1       128       128  0.0002   \n",
       "35     setsum             100               1       128       256  0.0002   \n",
       "24     setsum             100               1       128       128  0.0002   \n",
       "34     setsum             100               1       128       256  0.0002   \n",
       "27     setsum             100               1       128       128  0.0002   \n",
       "\n",
       "        lr2  dropout  batchsize                    embed_file  \\\n",
       "26  0.00002      0.1        128  all/embed_mat_pen_2_1e-6.npy   \n",
       "35  0.00005      0.3        256  all/embed_mat_pen_2_1e-6.npy   \n",
       "24  0.00001      0.1        256  all/embed_mat_pen_2_1e-6.npy   \n",
       "34  0.00005      0.1        256  all/embed_mat_pen_2_1e-6.npy   \n",
       "27  0.00002      0.5        256  all/embed_mat_pen_2_1e-6.npy   \n",
       "\n",
       "                   data_file  sep_dx1  tst_seed  n_fold  auc_mean  auc_cil  \\\n",
       "26  cohorts/ami/ami_pred.csv        0         0       7    0.7286  (0.7275   \n",
       "35  cohorts/ami/ami_pred.csv        0         0       7    0.7286  (0.7278   \n",
       "24  cohorts/ami/ami_pred.csv        0         0       7    0.7287  (0.7275   \n",
       "34  cohorts/ami/ami_pred.csv        0         0       7    0.7286  (0.7271   \n",
       "27  cohorts/ami/ami_pred.csv        0         0       7    0.7286  (0.7278   \n",
       "\n",
       "     auc_cih                             y_pred_file  \n",
       "26   0.7298)  output/y_pred_mat18_08_30_11_48_48.npy  \n",
       "35   0.7295)  output/y_pred_mat18_08_30_06_42_42.npy  \n",
       "24   0.7300)  output/y_pred_mat18_08_30_11_59_33.npy  \n",
       "34   0.7301)  output/y_pred_mat18_08_30_08_38_31.npy  \n",
       "27   0.7294)  output/y_pred_mat18_08_30_12_04_01.npy  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.loc[res.auc_mean>0.7285, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding + NN  with subset of codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for job_ind in range(4):\n",
    "    df = pd.read_csv('output/ht_result1001_'+str(job_ind)+'.csv', \n",
    "                     names=['model_name', 'code_embed_dim', 'hosp_embed_dim', 'fc_width', 'md_width', 'lr1', 'lr2', 'dropout',\n",
    "                            'batchsize', 'embed_file', 'cohort', 'tst_seed', 'n_fold', 'penalty', 'penalty_metric', 'count_cap', \n",
    "                            'DX_rarecutpoint', 'PR_rarecutpoint', 'auc_mean', 'auc_avg', 'auc_freeze', 'y_pred_file'], index_col=None)\n",
    "    res = pd.concat([res, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.loc[res.model_name=='embed_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>code_embed_dim</th>\n",
       "      <th>hosp_embed_dim</th>\n",
       "      <th>fc_width</th>\n",
       "      <th>md_width</th>\n",
       "      <th>lr1</th>\n",
       "      <th>lr2</th>\n",
       "      <th>dropout</th>\n",
       "      <th>batchsize</th>\n",
       "      <th>embed_file</th>\n",
       "      <th>...</th>\n",
       "      <th>n_fold</th>\n",
       "      <th>penalty</th>\n",
       "      <th>penalty_metric</th>\n",
       "      <th>count_cap</th>\n",
       "      <th>DX_rarecutpoint</th>\n",
       "      <th>PR_rarecutpoint</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_avg</th>\n",
       "      <th>auc_freeze</th>\n",
       "      <th>y_pred_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71854</td>\n",
       "      <td>0.72020</td>\n",
       "      <td>0.71711</td>\n",
       "      <td>output/y_pred_mat18_10_03_04_03_11.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71977</td>\n",
       "      <td>0.72173</td>\n",
       "      <td>0.71875</td>\n",
       "      <td>output/y_pred_mat18_10_03_04_32_18.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72522</td>\n",
       "      <td>0.72696</td>\n",
       "      <td>0.72325</td>\n",
       "      <td>output/y_pred_mat18_10_03_05_02_18.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71286</td>\n",
       "      <td>0.71549</td>\n",
       "      <td>0.71256</td>\n",
       "      <td>output/y_pred_mat18_10_03_05_34_03.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.70873</td>\n",
       "      <td>0.71141</td>\n",
       "      <td>0.70968</td>\n",
       "      <td>output/y_pred_mat18_10_03_06_07_20.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71711</td>\n",
       "      <td>0.71959</td>\n",
       "      <td>0.71640</td>\n",
       "      <td>output/y_pred_mat18_10_03_06_30_57.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71793</td>\n",
       "      <td>0.72071</td>\n",
       "      <td>0.71688</td>\n",
       "      <td>output/y_pred_mat18_10_03_06_56_58.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72293</td>\n",
       "      <td>0.72548</td>\n",
       "      <td>0.72196</td>\n",
       "      <td>output/y_pred_mat18_10_03_07_22_56.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71236</td>\n",
       "      <td>0.71453</td>\n",
       "      <td>0.71221</td>\n",
       "      <td>output/y_pred_mat18_10_03_07_46_51.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.70821</td>\n",
       "      <td>0.71076</td>\n",
       "      <td>0.70844</td>\n",
       "      <td>output/y_pred_mat18_10_03_08_11_43.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71723</td>\n",
       "      <td>0.72062</td>\n",
       "      <td>0.71692</td>\n",
       "      <td>output/y_pred_mat18_10_03_08_35_03.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71853</td>\n",
       "      <td>0.72099</td>\n",
       "      <td>0.71741</td>\n",
       "      <td>output/y_pred_mat18_10_03_09_00_59.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72344</td>\n",
       "      <td>0.72629</td>\n",
       "      <td>0.72262</td>\n",
       "      <td>output/y_pred_mat18_10_03_09_23_57.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71379</td>\n",
       "      <td>0.71601</td>\n",
       "      <td>0.71339</td>\n",
       "      <td>output/y_pred_mat18_10_03_09_56_12.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71009</td>\n",
       "      <td>0.71229</td>\n",
       "      <td>0.70927</td>\n",
       "      <td>output/y_pred_mat18_10_03_10_29_24.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71819</td>\n",
       "      <td>0.71988</td>\n",
       "      <td>0.71718</td>\n",
       "      <td>output/y_pred_mat18_10_03_11_00_11.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72016</td>\n",
       "      <td>0.72193</td>\n",
       "      <td>0.71890</td>\n",
       "      <td>output/y_pred_mat18_10_03_11_30_07.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72496</td>\n",
       "      <td>0.72680</td>\n",
       "      <td>0.72423</td>\n",
       "      <td>output/y_pred_mat18_10_03_11_59_46.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71500</td>\n",
       "      <td>0.71696</td>\n",
       "      <td>0.71463</td>\n",
       "      <td>output/y_pred_mat18_10_04_12_23_00.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71217</td>\n",
       "      <td>0.71411</td>\n",
       "      <td>0.71183</td>\n",
       "      <td>output/y_pred_mat18_10_04_12_45_58.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71751</td>\n",
       "      <td>0.71936</td>\n",
       "      <td>0.71660</td>\n",
       "      <td>output/y_pred_mat18_10_04_01_14_27.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71969</td>\n",
       "      <td>0.72185</td>\n",
       "      <td>0.71861</td>\n",
       "      <td>output/y_pred_mat18_10_04_01_44_52.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72424</td>\n",
       "      <td>0.72625</td>\n",
       "      <td>0.72315</td>\n",
       "      <td>output/y_pred_mat18_10_04_02_14_31.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71420</td>\n",
       "      <td>0.71593</td>\n",
       "      <td>0.71327</td>\n",
       "      <td>output/y_pred_mat18_10_04_02_45_39.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71199</td>\n",
       "      <td>0.71367</td>\n",
       "      <td>0.71137</td>\n",
       "      <td>output/y_pred_mat18_10_04_03_18_59.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71698</td>\n",
       "      <td>0.71959</td>\n",
       "      <td>0.71534</td>\n",
       "      <td>output/y_pred_mat18_10_04_03_49_57.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71927</td>\n",
       "      <td>0.72210</td>\n",
       "      <td>0.71814</td>\n",
       "      <td>output/y_pred_mat18_10_04_04_23_49.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72331</td>\n",
       "      <td>0.72622</td>\n",
       "      <td>0.72231</td>\n",
       "      <td>output/y_pred_mat18_10_04_04_53_22.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71461</td>\n",
       "      <td>0.71644</td>\n",
       "      <td>0.71409</td>\n",
       "      <td>output/y_pred_mat18_10_04_05_16_38.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71123</td>\n",
       "      <td>0.71338</td>\n",
       "      <td>0.71102</td>\n",
       "      <td>output/y_pred_mat18_10_04_05_41_02.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72314</td>\n",
       "      <td>0.72572</td>\n",
       "      <td>0.72237</td>\n",
       "      <td>output/y_pred_mat18_10_04_05_08_46.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71225</td>\n",
       "      <td>0.71484</td>\n",
       "      <td>0.71148</td>\n",
       "      <td>output/y_pred_mat18_10_04_05_41_13.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72401</td>\n",
       "      <td>0.72693</td>\n",
       "      <td>0.72306</td>\n",
       "      <td>output/y_pred_mat18_10_04_06_11_25.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71677</td>\n",
       "      <td>0.71873</td>\n",
       "      <td>0.71533</td>\n",
       "      <td>output/y_pred_mat18_10_04_06_40_56.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71557</td>\n",
       "      <td>0.71755</td>\n",
       "      <td>0.71351</td>\n",
       "      <td>output/y_pred_mat18_10_04_07_10_32.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72539</td>\n",
       "      <td>0.72684</td>\n",
       "      <td>0.72447</td>\n",
       "      <td>output/y_pred_mat18_10_04_07_35_02.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71467</td>\n",
       "      <td>0.71645</td>\n",
       "      <td>0.71426</td>\n",
       "      <td>output/y_pred_mat18_10_04_07_59_16.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72565</td>\n",
       "      <td>0.72755</td>\n",
       "      <td>0.72517</td>\n",
       "      <td>output/y_pred_mat18_10_04_08_22_34.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71522</td>\n",
       "      <td>0.71784</td>\n",
       "      <td>0.71458</td>\n",
       "      <td>output/y_pred_mat18_10_04_08_55_09.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71384</td>\n",
       "      <td>0.71651</td>\n",
       "      <td>0.71312</td>\n",
       "      <td>output/y_pred_mat18_10_04_09_25_49.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72579</td>\n",
       "      <td>0.72774</td>\n",
       "      <td>0.72474</td>\n",
       "      <td>output/y_pred_mat18_10_04_09_55_17.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71455</td>\n",
       "      <td>0.71633</td>\n",
       "      <td>0.71415</td>\n",
       "      <td>output/y_pred_mat18_10_04_10_27_56.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72636</td>\n",
       "      <td>0.72838</td>\n",
       "      <td>0.72565</td>\n",
       "      <td>output/y_pred_mat18_10_04_11_00_15.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71626</td>\n",
       "      <td>0.71819</td>\n",
       "      <td>0.71575</td>\n",
       "      <td>output/y_pred_mat18_10_04_11_30_56.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71488</td>\n",
       "      <td>0.71726</td>\n",
       "      <td>0.71456</td>\n",
       "      <td>output/y_pred_mat18_10_05_12_04_34.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72396</td>\n",
       "      <td>0.72630</td>\n",
       "      <td>0.72379</td>\n",
       "      <td>output/y_pred_mat18_10_05_12_28_15.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71332</td>\n",
       "      <td>0.71520</td>\n",
       "      <td>0.71174</td>\n",
       "      <td>output/y_pred_mat18_10_05_12_53_17.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72563</td>\n",
       "      <td>0.72804</td>\n",
       "      <td>0.72553</td>\n",
       "      <td>output/y_pred_mat18_10_05_01_17_47.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71562</td>\n",
       "      <td>0.71742</td>\n",
       "      <td>0.71492</td>\n",
       "      <td>output/y_pred_mat18_10_05_01_41_18.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71433</td>\n",
       "      <td>0.71656</td>\n",
       "      <td>0.71357</td>\n",
       "      <td>output/y_pred_mat18_10_05_02_07_30.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72298</td>\n",
       "      <td>0.72598</td>\n",
       "      <td>0.72267</td>\n",
       "      <td>output/y_pred_mat18_10_05_02_29_47.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71134</td>\n",
       "      <td>0.71424</td>\n",
       "      <td>0.71027</td>\n",
       "      <td>output/y_pred_mat18_10_05_02_52_45.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72385</td>\n",
       "      <td>0.72683</td>\n",
       "      <td>0.72324</td>\n",
       "      <td>output/y_pred_mat18_10_05_03_17_09.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71721</td>\n",
       "      <td>0.71913</td>\n",
       "      <td>0.71654</td>\n",
       "      <td>output/y_pred_mat18_10_05_03_41_06.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71574</td>\n",
       "      <td>0.71779</td>\n",
       "      <td>0.71498</td>\n",
       "      <td>output/y_pred_mat18_10_05_04_03_51.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72365</td>\n",
       "      <td>0.72589</td>\n",
       "      <td>0.72420</td>\n",
       "      <td>output/y_pred_mat18_10_05_04_25_55.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71374</td>\n",
       "      <td>0.71567</td>\n",
       "      <td>0.71349</td>\n",
       "      <td>output/y_pred_mat18_10_05_04_50_06.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72543</td>\n",
       "      <td>0.72766</td>\n",
       "      <td>0.72451</td>\n",
       "      <td>output/y_pred_mat18_10_05_05_13_41.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71746</td>\n",
       "      <td>0.71926</td>\n",
       "      <td>0.71700</td>\n",
       "      <td>output/y_pred_mat18_10_05_05_38_41.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>setsum_nn</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pretrain</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71563</td>\n",
       "      <td>0.71758</td>\n",
       "      <td>0.71543</td>\n",
       "      <td>output/y_pred_mat18_10_05_06_02_06.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>330 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_name  code_embed_dim  hosp_embed_dim  fc_width  md_width     lr1  \\\n",
       "0    setsum_nn             200               1      1024       256  0.0002   \n",
       "1    setsum_nn             200               1      1024       256  0.0002   \n",
       "2    setsum_nn             200               1      1024       256  0.0002   \n",
       "3    setsum_nn             200               1       512       256  0.0002   \n",
       "4    setsum_nn             200               1       512       256  0.0002   \n",
       "5    setsum_nn             300               1      1024       256  0.0002   \n",
       "6    setsum_nn             300               1      1024       256  0.0002   \n",
       "7    setsum_nn             300               1      1024       256  0.0002   \n",
       "8    setsum_nn             300               1      1024       256  0.0002   \n",
       "9    setsum_nn             300               1      1024       256  0.0002   \n",
       "10   setsum_nn             200               1      1024       128  0.0002   \n",
       "11   setsum_nn             200               1      1024       128  0.0002   \n",
       "12   setsum_nn             200               1      1024       128  0.0002   \n",
       "13   setsum_nn             200               1      1024       256  0.0002   \n",
       "14   setsum_nn             200               1      1024       256  0.0002   \n",
       "15   setsum_nn             200               1       512       256  0.0002   \n",
       "16   setsum_nn             200               1       512       256  0.0002   \n",
       "17   setsum_nn             200               1       512       256  0.0002   \n",
       "18   setsum_nn             300               1       512       128  0.0002   \n",
       "19   setsum_nn             300               1       512       128  0.0002   \n",
       "20   setsum_nn             200               1      1024       256  0.0002   \n",
       "21   setsum_nn             200               1      1024       256  0.0002   \n",
       "22   setsum_nn             200               1      1024       256  0.0002   \n",
       "23   setsum_nn             300               1      1024       256  0.0002   \n",
       "24   setsum_nn             300               1      1024       256  0.0002   \n",
       "25   setsum_nn             200               1       512       128  0.0002   \n",
       "26   setsum_nn             200               1       512       128  0.0002   \n",
       "27   setsum_nn             200               1       512       128  0.0002   \n",
       "28   setsum_nn             300               1       512       128  0.0002   \n",
       "29   setsum_nn             300               1       512       128  0.0002   \n",
       "..         ...             ...             ...       ...       ...     ...   \n",
       "300  setsum_nn             200               1       512       128  0.0002   \n",
       "301  setsum_nn             200               1       512       128  0.0002   \n",
       "302  setsum_nn             200               1       512       128  0.0002   \n",
       "303  setsum_nn             200               1       512       128  0.0002   \n",
       "304  setsum_nn             200               1       512       128  0.0002   \n",
       "305  setsum_nn             300               1      1024       128  0.0002   \n",
       "306  setsum_nn             300               1      1024       128  0.0002   \n",
       "307  setsum_nn             300               1      1024       128  0.0002   \n",
       "308  setsum_nn             200               1      1024       128  0.0002   \n",
       "309  setsum_nn             200               1      1024       128  0.0002   \n",
       "310  setsum_nn             200               1       512       128  0.0002   \n",
       "311  setsum_nn             200               1       512       128  0.0002   \n",
       "312  setsum_nn             200               1       512       128  0.0002   \n",
       "313  setsum_nn             300               1       512       128  0.0002   \n",
       "314  setsum_nn             300               1       512       128  0.0002   \n",
       "315  setsum_nn             200               1      1024       256  0.0002   \n",
       "316  setsum_nn             200               1      1024       256  0.0002   \n",
       "317  setsum_nn             200               1      1024       256  0.0002   \n",
       "318  setsum_nn             300               1      1024       256  0.0002   \n",
       "319  setsum_nn             300               1      1024       256  0.0002   \n",
       "320  setsum_nn             200               1       512       128  0.0002   \n",
       "321  setsum_nn             200               1       512       128  0.0002   \n",
       "322  setsum_nn             200               1       512       128  0.0002   \n",
       "323  setsum_nn             300               1      1024       128  0.0002   \n",
       "324  setsum_nn             300               1      1024       128  0.0002   \n",
       "325  setsum_nn             200               1       512       256  0.0002   \n",
       "326  setsum_nn             200               1       512       256  0.0002   \n",
       "327  setsum_nn             200               1       512       256  0.0002   \n",
       "328  setsum_nn             300               1      1024       128  0.0002   \n",
       "329  setsum_nn             300               1      1024       128  0.0002   \n",
       "\n",
       "         lr2  dropout  batchsize embed_file  \\\n",
       "0    0.00002      0.3        256   pretrain   \n",
       "1    0.00002      0.3        256   pretrain   \n",
       "2    0.00002      0.3        256   pretrain   \n",
       "3    0.00002      0.3        256   pretrain   \n",
       "4    0.00002      0.3        256   pretrain   \n",
       "5    0.00002      0.3        512   pretrain   \n",
       "6    0.00002      0.3        512   pretrain   \n",
       "7    0.00002      0.3        512   pretrain   \n",
       "8    0.00002      0.3        512   pretrain   \n",
       "9    0.00002      0.3        512   pretrain   \n",
       "10   0.00002      0.3        512   pretrain   \n",
       "11   0.00002      0.3        512   pretrain   \n",
       "12   0.00002      0.3        512   pretrain   \n",
       "13   0.00002      0.3        256   pretrain   \n",
       "14   0.00002      0.3        256   pretrain   \n",
       "15   0.00002      0.3        256   pretrain   \n",
       "16   0.00002      0.3        256   pretrain   \n",
       "17   0.00002      0.3        256   pretrain   \n",
       "18   0.00002      0.3        512   pretrain   \n",
       "19   0.00002      0.3        512   pretrain   \n",
       "20   0.00002      0.3        256   pretrain   \n",
       "21   0.00002      0.3        256   pretrain   \n",
       "22   0.00002      0.3        256   pretrain   \n",
       "23   0.00002      0.3        256   pretrain   \n",
       "24   0.00002      0.3        256   pretrain   \n",
       "25   0.00002      0.3        256   pretrain   \n",
       "26   0.00002      0.3        256   pretrain   \n",
       "27   0.00002      0.3        256   pretrain   \n",
       "28   0.00002      0.3        512   pretrain   \n",
       "29   0.00002      0.3        512   pretrain   \n",
       "..       ...      ...        ...        ...   \n",
       "300  0.00002      0.3        256   pretrain   \n",
       "301  0.00002      0.3        256   pretrain   \n",
       "302  0.00002      0.3        256   pretrain   \n",
       "303  0.00002      0.3        256   pretrain   \n",
       "304  0.00002      0.3        256   pretrain   \n",
       "305  0.00002      0.3        512   pretrain   \n",
       "306  0.00002      0.3        512   pretrain   \n",
       "307  0.00002      0.3        512   pretrain   \n",
       "308  0.00002      0.3        256   pretrain   \n",
       "309  0.00002      0.3        256   pretrain   \n",
       "310  0.00002      0.3        256   pretrain   \n",
       "311  0.00002      0.3        256   pretrain   \n",
       "312  0.00002      0.3        256   pretrain   \n",
       "313  0.00002      0.3        256   pretrain   \n",
       "314  0.00002      0.3        256   pretrain   \n",
       "315  0.00002      0.3        512   pretrain   \n",
       "316  0.00002      0.3        512   pretrain   \n",
       "317  0.00002      0.3        512   pretrain   \n",
       "318  0.00002      0.3        512   pretrain   \n",
       "319  0.00002      0.3        512   pretrain   \n",
       "320  0.00002      0.3        512   pretrain   \n",
       "321  0.00002      0.3        512   pretrain   \n",
       "322  0.00002      0.3        512   pretrain   \n",
       "323  0.00002      0.3        512   pretrain   \n",
       "324  0.00002      0.3        512   pretrain   \n",
       "325  0.00002      0.3        512   pretrain   \n",
       "326  0.00002      0.3        512   pretrain   \n",
       "327  0.00002      0.3        512   pretrain   \n",
       "328  0.00002      0.3        512   pretrain   \n",
       "329  0.00002      0.3        512   pretrain   \n",
       "\n",
       "                      ...                   n_fold  penalty  penalty_metric  \\\n",
       "0                     ...                        5      1.0          cosine   \n",
       "1                     ...                        5      1.0          cosine   \n",
       "2                     ...                        5      1.0          cosine   \n",
       "3                     ...                        5      0.0          cosine   \n",
       "4                     ...                        5      0.0          cosine   \n",
       "5                     ...                        5      0.0          cosine   \n",
       "6                     ...                        5      0.0          cosine   \n",
       "7                     ...                        5      0.0          cosine   \n",
       "8                     ...                        5      0.0          cosine   \n",
       "9                     ...                        5      0.0          cosine   \n",
       "10                    ...                        5      0.0          cosine   \n",
       "11                    ...                        5      0.0          cosine   \n",
       "12                    ...                        5      0.0          cosine   \n",
       "13                    ...                        5      0.5          cosine   \n",
       "14                    ...                        5      0.5          cosine   \n",
       "15                    ...                        5      0.5          cosine   \n",
       "16                    ...                        5      0.5          cosine   \n",
       "17                    ...                        5      0.5          cosine   \n",
       "18                    ...                        5      1.0          cosine   \n",
       "19                    ...                        5      1.0          cosine   \n",
       "20                    ...                        5      0.5          cosine   \n",
       "21                    ...                        5      0.5          cosine   \n",
       "22                    ...                        5      0.5          cosine   \n",
       "23                    ...                        5      1.0          cosine   \n",
       "24                    ...                        5      1.0          cosine   \n",
       "25                    ...                        5      0.0          cosine   \n",
       "26                    ...                        5      0.0          cosine   \n",
       "27                    ...                        5      0.0          cosine   \n",
       "28                    ...                        5      0.5          cosine   \n",
       "29                    ...                        5      0.5          cosine   \n",
       "..                    ...                      ...      ...             ...   \n",
       "300                   ...                        5      0.0          cosine   \n",
       "301                   ...                        5      0.0          cosine   \n",
       "302                   ...                        5      0.0          cosine   \n",
       "303                   ...                        5      1.0          cosine   \n",
       "304                   ...                        5      1.0          cosine   \n",
       "305                   ...                        5      0.5          cosine   \n",
       "306                   ...                        5      0.5          cosine   \n",
       "307                   ...                        5      0.5          cosine   \n",
       "308                   ...                        5      0.0          cosine   \n",
       "309                   ...                        5      0.0          cosine   \n",
       "310                   ...                        5      1.0          cosine   \n",
       "311                   ...                        5      1.0          cosine   \n",
       "312                   ...                        5      1.0          cosine   \n",
       "313                   ...                        5      0.5          cosine   \n",
       "314                   ...                        5      0.5          cosine   \n",
       "315                   ...                        5      0.5          cosine   \n",
       "316                   ...                        5      0.5          cosine   \n",
       "317                   ...                        5      0.5          cosine   \n",
       "318                   ...                        5      0.5          cosine   \n",
       "319                   ...                        5      0.5          cosine   \n",
       "320                   ...                        5      0.0          cosine   \n",
       "321                   ...                        5      0.0          cosine   \n",
       "322                   ...                        5      0.0          cosine   \n",
       "323                   ...                        5      1.0          cosine   \n",
       "324                   ...                        5      1.0          cosine   \n",
       "325                   ...                        5      1.0          cosine   \n",
       "326                   ...                        5      1.0          cosine   \n",
       "327                   ...                        5      1.0          cosine   \n",
       "328                   ...                        5      0.5          cosine   \n",
       "329                   ...                        5      0.5          cosine   \n",
       "\n",
       "     count_cap DX_rarecutpoint  PR_rarecutpoint  auc_mean  auc_avg  \\\n",
       "0            5              20               10   0.71854  0.72020   \n",
       "1            5              20               10   0.71977  0.72173   \n",
       "2            5              20               10   0.72522  0.72696   \n",
       "3            5              20               10   0.71286  0.71549   \n",
       "4            5              20               10   0.70873  0.71141   \n",
       "5            0              20               10   0.71711  0.71959   \n",
       "6            0              20               10   0.71793  0.72071   \n",
       "7            0              20               10   0.72293  0.72548   \n",
       "8            0              20               10   0.71236  0.71453   \n",
       "9            0              20               10   0.70821  0.71076   \n",
       "10           5              20               10   0.71723  0.72062   \n",
       "11           5              20               10   0.71853  0.72099   \n",
       "12           5              20               10   0.72344  0.72629   \n",
       "13           0              20               10   0.71379  0.71601   \n",
       "14           0              20               10   0.71009  0.71229   \n",
       "15          20              20               10   0.71819  0.71988   \n",
       "16          20              20               10   0.72016  0.72193   \n",
       "17          20              20               10   0.72496  0.72680   \n",
       "18           5              20               10   0.71500  0.71696   \n",
       "19           5              20               10   0.71217  0.71411   \n",
       "20           5              20               10   0.71751  0.71936   \n",
       "21           5              20               10   0.71969  0.72185   \n",
       "22           5              20               10   0.72424  0.72625   \n",
       "23           5              20               10   0.71420  0.71593   \n",
       "24           5              20               10   0.71199  0.71367   \n",
       "25          20              20               10   0.71698  0.71959   \n",
       "26          20              20               10   0.71927  0.72210   \n",
       "27          20              20               10   0.72331  0.72622   \n",
       "28          20              20               10   0.71461  0.71644   \n",
       "29          20              20               10   0.71123  0.71338   \n",
       "..         ...             ...              ...       ...      ...   \n",
       "300         20              20               10   0.72314  0.72572   \n",
       "301         20              20               10   0.71225  0.71484   \n",
       "302         20              20               10   0.72401  0.72693   \n",
       "303         20              20               10   0.71677  0.71873   \n",
       "304         20              20               10   0.71557  0.71755   \n",
       "305         20              20               10   0.72539  0.72684   \n",
       "306         20              20               10   0.71467  0.71645   \n",
       "307         20              20               10   0.72565  0.72755   \n",
       "308          5              20               10   0.71522  0.71784   \n",
       "309          5              20               10   0.71384  0.71651   \n",
       "310          5              20               10   0.72579  0.72774   \n",
       "311          5              20               10   0.71455  0.71633   \n",
       "312          5              20               10   0.72636  0.72838   \n",
       "313          5              20               10   0.71626  0.71819   \n",
       "314          5              20               10   0.71488  0.71726   \n",
       "315          0              20               10   0.72396  0.72630   \n",
       "316          0              20               10   0.71332  0.71520   \n",
       "317          0              20               10   0.72563  0.72804   \n",
       "318          5              20               10   0.71562  0.71742   \n",
       "319          5              20               10   0.71433  0.71656   \n",
       "320          0              20               10   0.72298  0.72598   \n",
       "321          0              20               10   0.71134  0.71424   \n",
       "322          0              20               10   0.72385  0.72683   \n",
       "323         20              20               10   0.71721  0.71913   \n",
       "324         20              20               10   0.71574  0.71779   \n",
       "325          0              20               10   0.72365  0.72589   \n",
       "326          0              20               10   0.71374  0.71567   \n",
       "327          0              20               10   0.72543  0.72766   \n",
       "328         20              20               10   0.71746  0.71926   \n",
       "329         20              20               10   0.71563  0.71758   \n",
       "\n",
       "     auc_freeze                             y_pred_file  \n",
       "0       0.71711  output/y_pred_mat18_10_03_04_03_11.npy  \n",
       "1       0.71875  output/y_pred_mat18_10_03_04_32_18.npy  \n",
       "2       0.72325  output/y_pred_mat18_10_03_05_02_18.npy  \n",
       "3       0.71256  output/y_pred_mat18_10_03_05_34_03.npy  \n",
       "4       0.70968  output/y_pred_mat18_10_03_06_07_20.npy  \n",
       "5       0.71640  output/y_pred_mat18_10_03_06_30_57.npy  \n",
       "6       0.71688  output/y_pred_mat18_10_03_06_56_58.npy  \n",
       "7       0.72196  output/y_pred_mat18_10_03_07_22_56.npy  \n",
       "8       0.71221  output/y_pred_mat18_10_03_07_46_51.npy  \n",
       "9       0.70844  output/y_pred_mat18_10_03_08_11_43.npy  \n",
       "10      0.71692  output/y_pred_mat18_10_03_08_35_03.npy  \n",
       "11      0.71741  output/y_pred_mat18_10_03_09_00_59.npy  \n",
       "12      0.72262  output/y_pred_mat18_10_03_09_23_57.npy  \n",
       "13      0.71339  output/y_pred_mat18_10_03_09_56_12.npy  \n",
       "14      0.70927  output/y_pred_mat18_10_03_10_29_24.npy  \n",
       "15      0.71718  output/y_pred_mat18_10_03_11_00_11.npy  \n",
       "16      0.71890  output/y_pred_mat18_10_03_11_30_07.npy  \n",
       "17      0.72423  output/y_pred_mat18_10_03_11_59_46.npy  \n",
       "18      0.71463  output/y_pred_mat18_10_04_12_23_00.npy  \n",
       "19      0.71183  output/y_pred_mat18_10_04_12_45_58.npy  \n",
       "20      0.71660  output/y_pred_mat18_10_04_01_14_27.npy  \n",
       "21      0.71861  output/y_pred_mat18_10_04_01_44_52.npy  \n",
       "22      0.72315  output/y_pred_mat18_10_04_02_14_31.npy  \n",
       "23      0.71327  output/y_pred_mat18_10_04_02_45_39.npy  \n",
       "24      0.71137  output/y_pred_mat18_10_04_03_18_59.npy  \n",
       "25      0.71534  output/y_pred_mat18_10_04_03_49_57.npy  \n",
       "26      0.71814  output/y_pred_mat18_10_04_04_23_49.npy  \n",
       "27      0.72231  output/y_pred_mat18_10_04_04_53_22.npy  \n",
       "28      0.71409  output/y_pred_mat18_10_04_05_16_38.npy  \n",
       "29      0.71102  output/y_pred_mat18_10_04_05_41_02.npy  \n",
       "..          ...                                     ...  \n",
       "300     0.72237  output/y_pred_mat18_10_04_05_08_46.npy  \n",
       "301     0.71148  output/y_pred_mat18_10_04_05_41_13.npy  \n",
       "302     0.72306  output/y_pred_mat18_10_04_06_11_25.npy  \n",
       "303     0.71533  output/y_pred_mat18_10_04_06_40_56.npy  \n",
       "304     0.71351  output/y_pred_mat18_10_04_07_10_32.npy  \n",
       "305     0.72447  output/y_pred_mat18_10_04_07_35_02.npy  \n",
       "306     0.71426  output/y_pred_mat18_10_04_07_59_16.npy  \n",
       "307     0.72517  output/y_pred_mat18_10_04_08_22_34.npy  \n",
       "308     0.71458  output/y_pred_mat18_10_04_08_55_09.npy  \n",
       "309     0.71312  output/y_pred_mat18_10_04_09_25_49.npy  \n",
       "310     0.72474  output/y_pred_mat18_10_04_09_55_17.npy  \n",
       "311     0.71415  output/y_pred_mat18_10_04_10_27_56.npy  \n",
       "312     0.72565  output/y_pred_mat18_10_04_11_00_15.npy  \n",
       "313     0.71575  output/y_pred_mat18_10_04_11_30_56.npy  \n",
       "314     0.71456  output/y_pred_mat18_10_05_12_04_34.npy  \n",
       "315     0.72379  output/y_pred_mat18_10_05_12_28_15.npy  \n",
       "316     0.71174  output/y_pred_mat18_10_05_12_53_17.npy  \n",
       "317     0.72553  output/y_pred_mat18_10_05_01_17_47.npy  \n",
       "318     0.71492  output/y_pred_mat18_10_05_01_41_18.npy  \n",
       "319     0.71357  output/y_pred_mat18_10_05_02_07_30.npy  \n",
       "320     0.72267  output/y_pred_mat18_10_05_02_29_47.npy  \n",
       "321     0.71027  output/y_pred_mat18_10_05_02_52_45.npy  \n",
       "322     0.72324  output/y_pred_mat18_10_05_03_17_09.npy  \n",
       "323     0.71654  output/y_pred_mat18_10_05_03_41_06.npy  \n",
       "324     0.71498  output/y_pred_mat18_10_05_04_03_51.npy  \n",
       "325     0.72420  output/y_pred_mat18_10_05_04_25_55.npy  \n",
       "326     0.71349  output/y_pred_mat18_10_05_04_50_06.npy  \n",
       "327     0.72451  output/y_pred_mat18_10_05_05_13_41.npy  \n",
       "328     0.71700  output/y_pred_mat18_10_05_05_38_41.npy  \n",
       "329     0.71543  output/y_pred_mat18_10_05_06_02_06.npy  \n",
       "\n",
       "[330 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_grouped = res.groupby(['code_embed_dim', 'fc_width', 'md_width', 'penalty', 'batchsize', 'count_cap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">auc_freeze</th>\n",
       "      <th colspan=\"2\" halign=\"left\">auc_mean</th>\n",
       "      <th colspan=\"2\" halign=\"left\">auc_avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code_embed_dim</th>\n",
       "      <th>fc_width</th>\n",
       "      <th>md_width</th>\n",
       "      <th>penalty</th>\n",
       "      <th>batchsize</th>\n",
       "      <th>count_cap</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">200</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">512</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">128</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.0</th>\n",
       "      <th>256</th>\n",
       "      <th>20</th>\n",
       "      <td>0.716274</td>\n",
       "      <td>20</td>\n",
       "      <td>0.717040</td>\n",
       "      <td>20</td>\n",
       "      <td>0.719784</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <th>0</th>\n",
       "      <td>0.716043</td>\n",
       "      <td>20</td>\n",
       "      <td>0.716647</td>\n",
       "      <td>20</td>\n",
       "      <td>0.719599</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <th>0.0</th>\n",
       "      <th>256</th>\n",
       "      <th>5</th>\n",
       "      <td>0.716623</td>\n",
       "      <td>10</td>\n",
       "      <td>0.717226</td>\n",
       "      <td>10</td>\n",
       "      <td>0.719562</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1024</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">128</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">256</th>\n",
       "      <th>5</th>\n",
       "      <td>0.716075</td>\n",
       "      <td>20</td>\n",
       "      <td>0.716861</td>\n",
       "      <td>20</td>\n",
       "      <td>0.719762</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.716289</td>\n",
       "      <td>10</td>\n",
       "      <td>0.717320</td>\n",
       "      <td>10</td>\n",
       "      <td>0.719926</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <th>5</th>\n",
       "      <td>0.716510</td>\n",
       "      <td>10</td>\n",
       "      <td>0.717119</td>\n",
       "      <td>10</td>\n",
       "      <td>0.720019</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <th>1024</th>\n",
       "      <th>256</th>\n",
       "      <th>0.0</th>\n",
       "      <th>512</th>\n",
       "      <th>0</th>\n",
       "      <td>0.715975</td>\n",
       "      <td>20</td>\n",
       "      <td>0.716324</td>\n",
       "      <td>20</td>\n",
       "      <td>0.718935</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             auc_freeze        \\\n",
       "                                                                   mean count   \n",
       "code_embed_dim fc_width md_width penalty batchsize count_cap                    \n",
       "200            512      128      0.0     256       20          0.716274    20   \n",
       "                                         512       0           0.716043    20   \n",
       "                        256      0.0     256       5           0.716623    10   \n",
       "               1024     128      0.0     256       5           0.716075    20   \n",
       "                                                   20          0.716289    10   \n",
       "                                         512       5           0.716510    10   \n",
       "300            1024     256      0.0     512       0           0.715975    20   \n",
       "\n",
       "                                                              auc_mean        \\\n",
       "                                                                  mean count   \n",
       "code_embed_dim fc_width md_width penalty batchsize count_cap                   \n",
       "200            512      128      0.0     256       20         0.717040    20   \n",
       "                                         512       0          0.716647    20   \n",
       "                        256      0.0     256       5          0.717226    10   \n",
       "               1024     128      0.0     256       5          0.716861    20   \n",
       "                                                   20         0.717320    10   \n",
       "                                         512       5          0.717119    10   \n",
       "300            1024     256      0.0     512       0          0.716324    20   \n",
       "\n",
       "                                                               auc_avg        \n",
       "                                                                  mean count  \n",
       "code_embed_dim fc_width md_width penalty batchsize count_cap                  \n",
       "200            512      128      0.0     256       20         0.719784    20  \n",
       "                                         512       0          0.719599    20  \n",
       "                        256      0.0     256       5          0.719562    10  \n",
       "               1024     128      0.0     256       5          0.719762    20  \n",
       "                                                   20         0.719926    10  \n",
       "                                         512       5          0.720019    10  \n",
       "300            1024     256      0.0     512       0          0.718935    20  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_grouped[['auc_freeze', 'auc_mean', 'auc_avg']].agg(['mean', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('output/ht_result1003embed_nn_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.read_csv('output/ht_result1003embed_nn_sub.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.loc[res.penalty==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OHE models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for job_ind in range(1):\n",
    "    df = pd.read_csv('output/ht_result0925_'+str(job_ind)+'.csv', \n",
    "                     names=['fc_width1', 'fc_width2', 'lr', 'dropout', 'batchsize', 'cohort', 'tst_seed', 'n_fold', \n",
    "                            'DX_rarecutpoint', 'PR_rarecutpoint', 'auc_mean', 'auc_avg', 'y_pred_file'], index_col=None)\n",
    "    res = pd.concat([res, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fc_width1</th>\n",
       "      <th>fc_width2</th>\n",
       "      <th>lr</th>\n",
       "      <th>dropout</th>\n",
       "      <th>batchsize</th>\n",
       "      <th>cohort</th>\n",
       "      <th>tst_seed</th>\n",
       "      <th>n_fold</th>\n",
       "      <th>DX_rarecutpoint</th>\n",
       "      <th>PR_rarecutpoint</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_avg</th>\n",
       "      <th>y_pred_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>ami</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71339</td>\n",
       "      <td>0.71610</td>\n",
       "      <td>output/y_pred_mat18_09_26_12_37_55.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>chf</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.61783</td>\n",
       "      <td>0.62129</td>\n",
       "      <td>output/y_pred_mat18_09_26_12_50_49.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pna</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.66755</td>\n",
       "      <td>0.67043</td>\n",
       "      <td>output/y_pred_mat18_09_26_01_14_10.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>ami</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71938</td>\n",
       "      <td>0.72227</td>\n",
       "      <td>output/y_pred_mat18_09_26_01_20_51.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>chf</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.62258</td>\n",
       "      <td>0.62686</td>\n",
       "      <td>output/y_pred_mat18_09_26_01_34_06.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pna</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.67248</td>\n",
       "      <td>0.67472</td>\n",
       "      <td>output/y_pred_mat18_09_26_01_56_41.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>ami</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.70725</td>\n",
       "      <td>0.71013</td>\n",
       "      <td>output/y_pred_mat18_09_26_02_03_15.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>chf</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.62727</td>\n",
       "      <td>0.63157</td>\n",
       "      <td>output/y_pred_mat18_09_26_02_16_32.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pna</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.66761</td>\n",
       "      <td>0.67088</td>\n",
       "      <td>output/y_pred_mat18_09_26_02_39_27.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>ami</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71382</td>\n",
       "      <td>0.71638</td>\n",
       "      <td>output/y_pred_mat18_09_26_02_46_03.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>chf</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.62566</td>\n",
       "      <td>0.62988</td>\n",
       "      <td>output/y_pred_mat18_09_26_02_59_21.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pna</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.67220</td>\n",
       "      <td>0.67531</td>\n",
       "      <td>output/y_pred_mat18_09_26_03_22_40.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>ami</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71510</td>\n",
       "      <td>0.71780</td>\n",
       "      <td>output/y_pred_mat18_09_26_03_28_53.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>chf</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.62636</td>\n",
       "      <td>0.62996</td>\n",
       "      <td>output/y_pred_mat18_09_26_03_42_05.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pna</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.66816</td>\n",
       "      <td>0.67011</td>\n",
       "      <td>output/y_pred_mat18_09_26_04_06_08.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>ami</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.70978</td>\n",
       "      <td>0.71214</td>\n",
       "      <td>output/y_pred_mat18_09_26_04_12_34.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>chf</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.62471</td>\n",
       "      <td>0.62859</td>\n",
       "      <td>output/y_pred_mat18_09_26_04_25_45.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pna</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.65954</td>\n",
       "      <td>0.66240</td>\n",
       "      <td>output/y_pred_mat18_09_26_04_49_25.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>ami</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.70653</td>\n",
       "      <td>0.70901</td>\n",
       "      <td>output/y_pred_mat18_09_26_04_55_33.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>chf</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.62151</td>\n",
       "      <td>0.62525</td>\n",
       "      <td>output/y_pred_mat18_09_26_05_08_13.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pna</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.66753</td>\n",
       "      <td>0.66960</td>\n",
       "      <td>output/y_pred_mat18_09_26_05_32_26.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>ami</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71184</td>\n",
       "      <td>0.71453</td>\n",
       "      <td>output/y_pred_mat18_09_26_05_38_54.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>chf</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.63224</td>\n",
       "      <td>0.63636</td>\n",
       "      <td>output/y_pred_mat18_09_26_05_52_02.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pna</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.66699</td>\n",
       "      <td>0.66899</td>\n",
       "      <td>output/y_pred_mat18_09_26_06_14_59.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>ami</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72035</td>\n",
       "      <td>0.72306</td>\n",
       "      <td>output/y_pred_mat18_09_26_06_21_31.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>chf</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.62885</td>\n",
       "      <td>0.63326</td>\n",
       "      <td>output/y_pred_mat18_09_26_06_34_15.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pna</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.66799</td>\n",
       "      <td>0.67020</td>\n",
       "      <td>output/y_pred_mat18_09_26_06_56_48.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>ami</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72035</td>\n",
       "      <td>0.72289</td>\n",
       "      <td>output/y_pred_mat18_09_26_07_03_12.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>chf</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.62468</td>\n",
       "      <td>0.62774</td>\n",
       "      <td>output/y_pred_mat18_09_26_07_15_49.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>pna</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.66460</td>\n",
       "      <td>0.66769</td>\n",
       "      <td>output/y_pred_mat18_09_26_07_38_37.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fc_width1  fc_width2      lr  dropout  batchsize cohort  tst_seed  n_fold  \\\n",
       "0        1024        256  0.0001      0.3        512    ami         0       5   \n",
       "1        1024        256  0.0001      0.3        512    chf         0       5   \n",
       "2        1024        256  0.0001      0.3        512    pna         0       5   \n",
       "3        1024        256  0.0001      0.3        512    ami         1       5   \n",
       "4        1024        256  0.0001      0.3        512    chf         1       5   \n",
       "5        1024        256  0.0001      0.3        512    pna         1       5   \n",
       "6        1024        256  0.0001      0.3        512    ami         2       5   \n",
       "7        1024        256  0.0001      0.3        512    chf         2       5   \n",
       "8        1024        256  0.0001      0.3        512    pna         2       5   \n",
       "9        1024        256  0.0001      0.3        512    ami         3       5   \n",
       "10       1024        256  0.0001      0.3        512    chf         3       5   \n",
       "11       1024        256  0.0001      0.3        512    pna         3       5   \n",
       "12       1024        256  0.0001      0.3        512    ami         4       5   \n",
       "13       1024        256  0.0001      0.3        512    chf         4       5   \n",
       "14       1024        256  0.0001      0.3        512    pna         4       5   \n",
       "15       1024        256  0.0001      0.3        512    ami         5       5   \n",
       "16       1024        256  0.0001      0.3        512    chf         5       5   \n",
       "17       1024        256  0.0001      0.3        512    pna         5       5   \n",
       "18       1024        256  0.0001      0.3        512    ami         6       5   \n",
       "19       1024        256  0.0001      0.3        512    chf         6       5   \n",
       "20       1024        256  0.0001      0.3        512    pna         6       5   \n",
       "21       1024        256  0.0001      0.3        512    ami         7       5   \n",
       "22       1024        256  0.0001      0.3        512    chf         7       5   \n",
       "23       1024        256  0.0001      0.3        512    pna         7       5   \n",
       "24       1024        256  0.0001      0.3        512    ami         8       5   \n",
       "25       1024        256  0.0001      0.3        512    chf         8       5   \n",
       "26       1024        256  0.0001      0.3        512    pna         8       5   \n",
       "27       1024        256  0.0001      0.3        512    ami         9       5   \n",
       "28       1024        256  0.0001      0.3        512    chf         9       5   \n",
       "29       1024        256  0.0001      0.3        512    pna         9       5   \n",
       "\n",
       "    DX_rarecutpoint  PR_rarecutpoint  auc_mean  auc_avg  \\\n",
       "0                10               10   0.71339  0.71610   \n",
       "1                10               10   0.61783  0.62129   \n",
       "2                10               10   0.66755  0.67043   \n",
       "3                10               10   0.71938  0.72227   \n",
       "4                10               10   0.62258  0.62686   \n",
       "5                10               10   0.67248  0.67472   \n",
       "6                10               10   0.70725  0.71013   \n",
       "7                10               10   0.62727  0.63157   \n",
       "8                10               10   0.66761  0.67088   \n",
       "9                10               10   0.71382  0.71638   \n",
       "10               10               10   0.62566  0.62988   \n",
       "11               10               10   0.67220  0.67531   \n",
       "12               10               10   0.71510  0.71780   \n",
       "13               10               10   0.62636  0.62996   \n",
       "14               10               10   0.66816  0.67011   \n",
       "15               10               10   0.70978  0.71214   \n",
       "16               10               10   0.62471  0.62859   \n",
       "17               10               10   0.65954  0.66240   \n",
       "18               10               10   0.70653  0.70901   \n",
       "19               10               10   0.62151  0.62525   \n",
       "20               10               10   0.66753  0.66960   \n",
       "21               10               10   0.71184  0.71453   \n",
       "22               10               10   0.63224  0.63636   \n",
       "23               10               10   0.66699  0.66899   \n",
       "24               10               10   0.72035  0.72306   \n",
       "25               10               10   0.62885  0.63326   \n",
       "26               10               10   0.66799  0.67020   \n",
       "27               10               10   0.72035  0.72289   \n",
       "28               10               10   0.62468  0.62774   \n",
       "29               10               10   0.66460  0.66769   \n",
       "\n",
       "                               y_pred_file  \n",
       "0   output/y_pred_mat18_09_26_12_37_55.npy  \n",
       "1   output/y_pred_mat18_09_26_12_50_49.npy  \n",
       "2   output/y_pred_mat18_09_26_01_14_10.npy  \n",
       "3   output/y_pred_mat18_09_26_01_20_51.npy  \n",
       "4   output/y_pred_mat18_09_26_01_34_06.npy  \n",
       "5   output/y_pred_mat18_09_26_01_56_41.npy  \n",
       "6   output/y_pred_mat18_09_26_02_03_15.npy  \n",
       "7   output/y_pred_mat18_09_26_02_16_32.npy  \n",
       "8   output/y_pred_mat18_09_26_02_39_27.npy  \n",
       "9   output/y_pred_mat18_09_26_02_46_03.npy  \n",
       "10  output/y_pred_mat18_09_26_02_59_21.npy  \n",
       "11  output/y_pred_mat18_09_26_03_22_40.npy  \n",
       "12  output/y_pred_mat18_09_26_03_28_53.npy  \n",
       "13  output/y_pred_mat18_09_26_03_42_05.npy  \n",
       "14  output/y_pred_mat18_09_26_04_06_08.npy  \n",
       "15  output/y_pred_mat18_09_26_04_12_34.npy  \n",
       "16  output/y_pred_mat18_09_26_04_25_45.npy  \n",
       "17  output/y_pred_mat18_09_26_04_49_25.npy  \n",
       "18  output/y_pred_mat18_09_26_04_55_33.npy  \n",
       "19  output/y_pred_mat18_09_26_05_08_13.npy  \n",
       "20  output/y_pred_mat18_09_26_05_32_26.npy  \n",
       "21  output/y_pred_mat18_09_26_05_38_54.npy  \n",
       "22  output/y_pred_mat18_09_26_05_52_02.npy  \n",
       "23  output/y_pred_mat18_09_26_06_14_59.npy  \n",
       "24  output/y_pred_mat18_09_26_06_21_31.npy  \n",
       "25  output/y_pred_mat18_09_26_06_34_15.npy  \n",
       "26  output/y_pred_mat18_09_26_06_56_48.npy  \n",
       "27  output/y_pred_mat18_09_26_07_03_12.npy  \n",
       "28  output/y_pred_mat18_09_26_07_15_49.npy  \n",
       "29  output/y_pred_mat18_09_26_07_38_37.npy  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_grouped = res.groupby(['cohort'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">auc_mean</th>\n",
       "      <th colspan=\"2\" halign=\"left\">auc_avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cohort</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ami</th>\n",
       "      <td>0.713779</td>\n",
       "      <td>10</td>\n",
       "      <td>0.716431</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chf</th>\n",
       "      <td>0.625169</td>\n",
       "      <td>10</td>\n",
       "      <td>0.629076</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pna</th>\n",
       "      <td>0.667465</td>\n",
       "      <td>10</td>\n",
       "      <td>0.670033</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        auc_mean         auc_avg      \n",
       "            mean count      mean count\n",
       "cohort                                \n",
       "ami     0.713779    10  0.716431    10\n",
       "chf     0.625169    10  0.629076    10\n",
       "pna     0.667465    10  0.670033    10"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_grouped[['auc_mean', 'auc_avg']].agg(['mean', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ami mean: 0.7138 (0.0016) avg: 0.7164 (0.0016)\n",
      "chf mean: 0.6252 (0.0013) avg: 0.6291 (0.0013)\n",
      "pna mean: 0.6675 (0.0012) avg: 0.6700 (0.0011)\n"
     ]
    }
   ],
   "source": [
    "for n, g in res_grouped:\n",
    "    print(n, 'mean: {0:.4f} ({1:.4f})'.format(g.auc_mean.mean(), g.auc_mean.std()/np.sqrt(len(g))), \n",
    "         'avg: {0:.4f} ({1:.4f})'.format(g.auc_avg.mean(), g.auc_avg.std()/np.sqrt(len(g))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
